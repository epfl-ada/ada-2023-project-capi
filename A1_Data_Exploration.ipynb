{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA CAPI Notebook for Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib\n",
    "import datetime as datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# load config and extract variables\n",
    "import config\n",
    "DATA_PATH = config.PATH_TO_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preparing the Data\n",
    "Load and clean up the paths, load into weighted graph structure etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in all data (except wikipedia articles)\n",
    "finished_paths = pd.read_csv(os.path.join(DATA_PATH, \"paths_finished.tsv\"), sep='\\t', skiprows=15, names=[\"hashedIpAddress\", \"timestamp\", \"durationInSec\", \"path\", \"rating\"])\n",
    "unfinished_paths = pd.read_csv(os.path.join(DATA_PATH, \"paths_unfinished.tsv\"), sep='\\t', skiprows=16, names=[\"hashedIpAddress\", \"timestamp\", \"durationInSec\", \"path\", \"target\", \"type\"])\n",
    "edges = pd.read_csv(os.path.join(DATA_PATH, \"links.tsv\"), sep='\\t', skiprows=15, names=[\"start\", \"end\"], encoding=\"utf-8\")\n",
    "articles = pd.read_csv(os.path.join(DATA_PATH, \"articles.tsv\"), sep='\\t', skiprows=12, names=[\"article\"], encoding=\"utf-8\")\n",
    "categories = pd.read_csv(os.path.join(DATA_PATH, \"categories.tsv\"), sep='\\t', skiprows=13, names=[\"article\", \"category\"], encoding=\"utf-8\")\n",
    "shortest_paths = np.genfromtxt(os.path.join(DATA_PATH, \"shortest-path-distance-matrix.txt\"), delimiter=1, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished_paths.info()\n",
    "display(finished_paths.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfinished_paths.info()\n",
    "display(unfinished_paths.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.info()\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles.info()\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories.head()\n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortest paths corresponds to numpy matrix, where 255 signifies no path (underscore in the .txt file), the diagonal is zero\n",
    "# the row index is the zero-based index corresponding to the index in the articles dataframe, same for the columns (target article)\n",
    "print((np.diag(shortest_paths)==0).all())\n",
    "shortest_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up edge list\n",
    "display(edges.head())\n",
    "edges[\"start\"] = edges.start.apply(urllib.parse.unquote)\n",
    "edges[\"end\"] = edges.end.apply(urllib.parse.unquote)\n",
    "display(edges.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format datetime as datetime object\n",
    "finished_paths[\"datetime\"] = finished_paths.timestamp.apply(datetime.datetime.fromtimestamp)\n",
    "unfinished_paths[\"datetime\"] = unfinished_paths.timestamp.apply(datetime.datetime.fromtimestamp)\n",
    "display(unfinished_paths.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up url encoding for articles\n",
    "display(articles.head())\n",
    "articles[\"article\"] = articles.article.apply(urllib.parse.unquote)\n",
    "display(articles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up url encoding for categories\n",
    "display(categories.head())\n",
    "categories[\"article\"] = categories.article.apply(urllib.parse.unquote)\n",
    "display(categories.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge articles and categories\n",
    "articles_categories = pd.merge(articles, categories, how=\"left\", on=\"article\")\n",
    "display(articles_categories.head())\n",
    "# 6 articles without category!\n",
    "print(\"Merge introduced {} NAs in category columns:\".format(articles_categories.category.isna().sum()))\n",
    "articles_categories[articles_categories.category.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create networkx graph from \n",
    "# TODO: create dweighted graphs, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Data Exploration\n",
    "Explore distribution of all relevant variables, analyze and potentially fill missing values, sÃ®mple summary stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Path lengths across finished and unfinished paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of path lengths disaggregated across finished and unfinished\n",
    "unfinished_paths[\"path_length\"] = unfinished_paths.path.apply(lambda el: len(el.split(\";\")))\n",
    "finished_paths[\"path_length\"] = finished_paths.path.apply(lambda el: len(el.split(\";\")))\n",
    "\n",
    "print(\"Finished Paths: Length\")\n",
    "display(finished_paths[\"path_length\"].describe())\n",
    "display(finished_paths.path_length.value_counts())\n",
    "\n",
    "print(\"Unfinished Paths: Length\")\n",
    "display(unfinished_paths[\"path_length\"].describe())\n",
    "unfinished_paths.path_length.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot of path lengths\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 4), sharey=True)\n",
    "\n",
    "sns.histplot(data=finished_paths, x=\"path_length\", ax=axes[0])\n",
    "axes[0].set_title(\"Finished Paths\")\n",
    "sns.histplot(data=unfinished_paths, x=\"path_length\", ax=axes[1], hue=\"type\")\n",
    "axes[1].set_title(\"Uninished Paths\")\n",
    "\n",
    "# --> highly skewed and many unlikely outcomes (e.g. unfinished paths path length = 1, did they really give up? or not play at all?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot comparing path lengths after cleaning up (e.g., kicking out top 10 percentiles, log transforms etc.) to better understand what is going on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Networkx graph objects \n",
    "degreehistograms, etc. etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next Idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Specific to Idea 1\n",
    "Explore specific questions as noted in notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate some summary stats on the wikipedia articles (length, number of hyperlinks etc. from the additional data given in teh task (not laoded yet)) to check some of our hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Specific to Idea 2\n",
    "Explore specific questions as noted in notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Specific to Idea 3\n",
    "Explore specific questions as noted in notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Specific to Idea 4\n",
    "Explore specific questions as noted in notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Specific to Idea 5\n",
    "Explore specific questions as noted in notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
