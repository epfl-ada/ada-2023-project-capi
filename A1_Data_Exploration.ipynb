{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA CAPI Notebook for Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib\n",
    "import datetime as datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# load config and extract variables\n",
    "import config\n",
    "DATA_PATH = config.PATH_TO_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preparing the Data\n",
    "Load and clean up the paths, load into weighted graph structure etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in all data (except wikipedia articles)\n",
    "finished_paths = pd.read_csv(os.path.join(DATA_PATH, \"paths_finished.tsv\"), sep='\\t', skiprows=15, names=[\"hashedIpAddress\", \"timestamp\", \"durationInSec\", \"path\", \"rating\"])\n",
    "unfinished_paths = pd.read_csv(os.path.join(DATA_PATH, \"paths_unfinished.tsv\"), sep='\\t', skiprows=16, names=[\"hashedIpAddress\", \"timestamp\", \"durationInSec\", \"path\", \"target\", \"type\"])\n",
    "edges = pd.read_csv(os.path.join(DATA_PATH, \"links.tsv\"), sep='\\t', skiprows=15, names=[\"start\", \"end\"], encoding=\"utf-8\")\n",
    "articles = pd.read_csv(os.path.join(DATA_PATH, \"articles.tsv\"), sep='\\t', skiprows=12, names=[\"article\"], encoding=\"utf-8\")\n",
    "categories = pd.read_csv(os.path.join(DATA_PATH, \"categories.tsv\"), sep='\\t', skiprows=13, names=[\"article\", \"category\"], encoding=\"utf-8\")\n",
    "shortest_paths = np.genfromtxt(os.path.join(DATA_PATH, \"shortest-path-distance-matrix.txt\"), delimiter=1, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished_paths.info()\n",
    "display(finished_paths.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfinished_paths.info()\n",
    "display(unfinished_paths.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.info()\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles.info()\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories.head()\n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortest paths corresponds to numpy matrix, where 255 signifies no path (underscore in the .txt file), the diagonal is zero\n",
    "# the row index is the zero-based index corresponding to the index in the articles dataframe, same for the columns (target article)\n",
    "print((np.diag(shortest_paths)==0).all())\n",
    "shortest_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up edge list\n",
    "display(edges.head())\n",
    "edges[\"start\"] = edges.start.apply(urllib.parse.unquote)\n",
    "edges[\"end\"] = edges.end.apply(urllib.parse.unquote)\n",
    "display(edges.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format datetime as datetime object\n",
    "finished_paths[\"datetime\"] = finished_paths.timestamp.apply(datetime.datetime.fromtimestamp)\n",
    "unfinished_paths[\"datetime\"] = unfinished_paths.timestamp.apply(datetime.datetime.fromtimestamp)\n",
    "display(unfinished_paths.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up url encoding for articles\n",
    "display(articles.head())\n",
    "articles[\"article\"] = articles.article.apply(urllib.parse.unquote)\n",
    "display(articles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up url encoding for categories\n",
    "display(categories.head())\n",
    "categories[\"article\"] = categories.article.apply(urllib.parse.unquote)\n",
    "display(categories.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge articles and categories\n",
    "articles_categories = pd.merge(articles, categories, how=\"left\", on=\"article\")\n",
    "display(articles_categories.head())\n",
    "# 6 articles without category!\n",
    "print(\"Merge introduced {} NAs in category columns:\".format(articles_categories.category.isna().sum()))\n",
    "articles_categories[articles_categories.category.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert paths to a readable format (lists)\n",
    "\n",
    "finished_paths_readable = finished_paths.copy()\n",
    "finished_paths_readable[\"readable_path\"] = finished_paths_readable[\"path\"].apply(lambda x: x.split(\";\"))\n",
    "finished_paths_readable[\"readable_path\"] = finished_paths_readable[\"readable_path\"].apply(lambda x: [urllib.parse.unquote(y) for y in x])\n",
    "\n",
    "unfinished_paths_readable = unfinished_paths.copy()\n",
    "unfinished_paths_readable[\"readable_path\"] = unfinished_paths_readable[\"path\"].apply(lambda x: x.split(\";\"))\n",
    "unfinished_paths_readable[\"readable_path\"] = unfinished_paths_readable[\"readable_path\"].apply(lambda x: [urllib.parse.unquote(y) for y in x])\n",
    "unfinished_paths_readable[\"target\"] = unfinished_paths_readable[\"target\"].apply(urllib.parse.unquote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to get all links between articles\n",
    "from itertools import tee\n",
    "def pairwise(iterable):\n",
    "    # from python docs - will be introduced in version 3.10\n",
    "    # pairwise('ABCDEFG') --> AB BC CD DE EF FG\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "\n",
    "def get_all_links(df, path_colname=\"path\"):\n",
    "    edge_counter = {}\n",
    "    for _, row in df.iterrows():\n",
    "        links = row['path'].split(';')\n",
    "        \n",
    "        edges = list(pairwise(links))\n",
    "\n",
    "        for edge in edges:\n",
    "            if edge in edge_counter:\n",
    "                edge_counter[edge] += 1\n",
    "            else:\n",
    "                edge_counter[edge] = 1\n",
    "\n",
    "    out = pd.Series(edge_counter).reset_index()\n",
    "    out.columns = [\"source\", \"target\", \"weight\"]\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all finished links\n",
    "finished_links = get_all_links(finished_paths)\n",
    "finished_links.sort_values(by=\"weight\", ascending=False) # TODO: what is up with these <<< signs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unfinished links\n",
    "unfinished_links = get_all_links(unfinished_paths)\n",
    "unfinished_links.sort_values(by=\"weight\", ascending=False) # TODO: what is up with these <<< signs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create newtorkx graph from finished paths\n",
    "finished_graph = nx.from_pandas_edgelist(finished_links,source=\"source\", target=\"target\", edge_attr=\"weight\")\n",
    "hist = nx.degree_histogram(finished_graph)\n",
    "plt.bar(range(len(hist)), hist)\n",
    "pd.Series(hist).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create newtorkx graph from unfinished paths\n",
    "unfinished_graph = nx.from_pandas_edgelist(unfinished_links,source=\"source\", target=\"target\", edge_attr=\"weight\")\n",
    "hist = nx.degree_histogram(unfinished_graph)\n",
    "plt.bar(range(len(hist)), hist)\n",
    "pd.Series(hist).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Data Exploration\n",
    "Explore distribution of all relevant variables, analyze and potentially fill missing values, sÃ®mple summary stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Path lengths across finished and unfinished paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of path lengths disaggregated across finished and unfinished\n",
    "unfinished_paths[\"path_length\"] = unfinished_paths.path.apply(lambda el: len(el.split(\";\")))\n",
    "finished_paths[\"path_length\"] = finished_paths.path.apply(lambda el: len(el.split(\";\")))\n",
    "\n",
    "print(\"Finished Paths: Length\")\n",
    "display(finished_paths[\"path_length\"].describe())\n",
    "display(finished_paths.path_length.value_counts())\n",
    "\n",
    "print(\"Unfinished Paths: Length\")\n",
    "display(unfinished_paths[\"path_length\"].describe())\n",
    "unfinished_paths.path_length.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot of path lengths\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 4), sharey=True)\n",
    "\n",
    "sns.histplot(data=finished_paths, x=\"path_length\", ax=axes[0])\n",
    "axes[0].set_title(\"Finished Paths\")\n",
    "sns.histplot(data=unfinished_paths, x=\"path_length\", ax=axes[1], hue=\"type\")\n",
    "axes[1].set_title(\"Uninished Paths\")\n",
    "\n",
    "# --> highly skewed and many unlikely outcomes (e.g. unfinished paths path length = 1, did they really give up? or not play at all?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot comparing path lengths after cleaning up (e.g., kicking out top 10 percentiles, log transforms etc.) to better understand what is going on\n",
    "\n",
    "# make plot of path lengths\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(14, 4), sharey=True)\n",
    "threshold = 30\n",
    "\n",
    "\n",
    "sns.histplot(x=finished_paths.path_length[finished_paths.path_length < threshold], ax=axes[0], discrete=True)\n",
    "axes[0].set_title(\"Finished Paths\")\n",
    "\n",
    "unfinished_clean = unfinished_paths[(unfinished_paths.path_length < threshold) & (unfinished_paths.type == \"restart\")]\n",
    "sns.histplot(data=unfinished_clean, x=\"path_length\", ax=axes[1], discrete=True,)\n",
    "axes[1].set_title(\"Uninished Paths - Restart\")\n",
    "\n",
    "unfinished_clean = unfinished_paths[(unfinished_paths.path_length < threshold) & (unfinished_paths.type == \"timeout\")]\n",
    "sns.histplot(data=unfinished_clean, x=\"path_length\", ax=axes[2], discrete=True,)\n",
    "axes[2].set_title(\"Uninished Paths - Timeout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore categories in the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing which categories are most represented in articles\n",
    "\n",
    "broad_categories = categories.copy()\n",
    "broad_categories[\"broad_category\"] = broad_categories[\"category\"].apply(lambda x: x.split(\".\")[1])\n",
    "\n",
    "count_articles = broad_categories.groupby(\"broad_category\").size()\n",
    "\n",
    "print(\"Below shows how many articles each of the broad categories are represented by\")\n",
    "display(count_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries for easy discovery of what categories an article belongs to\n",
    "article_to_category = {}\n",
    "article_to_broad_category = {}\n",
    "for i in range(len(broad_categories)):\n",
    "    if broad_categories.iloc[i][\"article\"] in article_to_category:\n",
    "        article_to_category[broad_categories.iloc[i][\"article\"]].append(broad_categories.iloc[i][\"category\"])\n",
    "        article_to_broad_category[broad_categories.iloc[i][\"article\"]].append(broad_categories.iloc[i][\"broad_category\"])\n",
    "    else:\n",
    "        article_to_category[broad_categories.iloc[i][\"article\"]] = [broad_categories.iloc[i][\"category\"]]\n",
    "        article_to_broad_category[broad_categories.iloc[i][\"article\"]] = [broad_categories.iloc[i][\"broad_category\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times each category has occured as a target in the finished paths\n",
    "\n",
    "# NOTE THAT SOME ARTICLES ARE REPRESENTED BY MULTIPLE CATEGORIES AND ARE COUNTED TWICE\n",
    "all_target_broad_categories_f = [article_to_broad_category[target] for target in [path[-1] for path in finished_paths_readable[\"readable_path\"]] if target in article_to_broad_category]\n",
    "all_target_broad_categories_f = [item for sublist in all_target_broad_categories_f for item in sublist]\n",
    "count_cats_finished_target = Counter(all_target_broad_categories_f)\n",
    "display(count_cats_finished_target)\n",
    "\n",
    "ax = plt.pie(count_cats_finished_target.values(), labels = count_cats_finished_target.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times each category has occured as a target in the finished paths\n",
    "\n",
    "# NOTE THAT SOME ARTICLES ARE REPRESENTED BY MULTIPLE CATEGORIES AND ARE COUNTED TWICE\n",
    "all_target_broad_categories_u = [article_to_broad_category[target] for target in unfinished_paths_readable[\"target\"] if target in article_to_broad_category]\n",
    "all_target_broad_categories_u = [item for sublist in all_target_broad_categories_u for item in sublist]\n",
    "count_cats_unfinished_target = Counter(all_target_broad_categories_u)\n",
    "count_cats_unfinished_target\n",
    "\n",
    "display(count_cats_unfinished_target)\n",
    "\n",
    "ax = plt.pie(count_cats_unfinished_target.values(), labels = count_cats_unfinished_target.keys())\n",
    "plt.show()\n",
    "\n",
    "# There are certain categories that show up more or less here proportionally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which countries are targets in finished paths\n",
    "\n",
    "country_targets_f = [target for target in [path[-1] for path in finished_paths_readable[\"readable_path\"]] if target in article_to_broad_category and \"Countries\" in article_to_broad_category[target]]\n",
    "count_countries_finished_target = Counter(country_targets_f)\n",
    "display(count_countries_finished_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which countries are targets in unfinished paths\n",
    "\n",
    "country_targets_u = [target for target in unfinished_paths_readable[\"target\"] if target in article_to_broad_category and \"Countries\" in article_to_broad_category[target]]\n",
    "count_countries_unfinished_target = Counter(country_targets_u)\n",
    "display(count_countries_unfinished_target)\n",
    "\n",
    "# There are certainly some trends here. Haiti, Samoa, and the Gaza Strip, for example, are over-represented in the unfinished paths\n",
    "# when compared to the finished paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In fact we can see that there are some countries that occured as a target more in unfinished paths than in finished paths\n",
    "count_countries_unfinished_target - count_countries_finished_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_country_counts = count_countries_unfinished_target + count_countries_finished_target\n",
    "country_percent_in_unfinished = total_country_counts.copy()\n",
    "country_percent_in_finished = total_country_counts.copy()\n",
    "\n",
    "for item, count in country_percent_in_unfinished.items():\n",
    "    country_percent_in_unfinished[item] = count_countries_unfinished_target[item] / total_country_counts[item]\n",
    "\n",
    "for item, count in country_percent_in_finished.items():\n",
    "    country_percent_in_finished[item] = count_countries_finished_target[item] / total_country_counts[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_percent_in_unfinished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_percent_in_finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Networkx graph objects \n",
    "degreehistograms, etc. etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next Idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Specific to Idea 1\n",
    "Explore specific questions as noted in notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate some summary stats on the wikipedia articles (length, number of hyperlinks etc. from the additional data given in teh task (not laoded yet)) to check some of our hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Specific to Idea 2\n",
    "Explore specific questions as noted in notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Specific to Idea 3\n",
    "Explore specific questions as noted in notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Specific to Idea 4\n",
    "Explore specific questions as noted in notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Specific to Idea 5\n",
    "Explore specific questions as noted in notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
