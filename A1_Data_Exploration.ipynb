{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA CAPI Notebook for Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/arcivelekoglu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/arcivelekoglu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib\n",
    "import datetime as datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from scipy import stats \n",
    "\n",
    "import textstat\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt') # Punkt tokenizer\n",
    "nltk.download('stopwords') # Commong stopwords\n",
    "\n",
    "# load config and extract variables\n",
    "import config\n",
    "DATA_PATH = config.PATH_TO_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preparing the Data\n",
    "Load and clean up the paths, load into weighted graph structure etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in all data (except wikipedia articles)\n",
    "finished_paths = pd.read_csv(os.path.join(DATA_PATH, \"wikispeedia_paths-and-graph/paths_finished.tsv\"), sep='\\t', skiprows=15, names=[\"hashedIpAddress\", \"timestamp\", \"durationInSec\", \"path\", \"rating\"])\n",
    "unfinished_paths = pd.read_csv(os.path.join(DATA_PATH, \"wikispeedia_paths-and-graph/paths_unfinished.tsv\"), sep='\\t', skiprows=16, names=[\"hashedIpAddress\", \"timestamp\", \"durationInSec\", \"path\", \"target\", \"type\"])\n",
    "edges = pd.read_csv(os.path.join(DATA_PATH, \"wikispeedia_paths-and-graph/links.tsv\"), sep='\\t', skiprows=15, names=[\"start\", \"end\"], encoding=\"utf-8\")\n",
    "articles = pd.read_csv(os.path.join(DATA_PATH, \"wikispeedia_paths-and-graph/articles.tsv\"), sep='\\t', skiprows=12, names=[\"article\"], encoding=\"utf-8\")\n",
    "categories = pd.read_csv(os.path.join(DATA_PATH, \"wikispeedia_paths-and-graph/categories.tsv\"), sep='\\t', skiprows=13, names=[\"article\", \"category\"], encoding=\"utf-8\")\n",
    "shortest_paths = np.genfromtxt(os.path.join(DATA_PATH, \"wikispeedia_paths-and-graph/shortest-path-distance-matrix.txt\"), delimiter=1, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51318 entries, 0 to 51317\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   hashedIpAddress  51315 non-null  object \n",
      " 1   timestamp        51318 non-null  int64  \n",
      " 2   durationInSec    51318 non-null  int64  \n",
      " 3   path             51318 non-null  object \n",
      " 4   rating           28501 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 2.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashedIpAddress</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>durationInSec</th>\n",
       "      <th>path</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6a3701d319fc3754</td>\n",
       "      <td>1297740409</td>\n",
       "      <td>166</td>\n",
       "      <td>14th_century;15th_century;16th_century;Pacific...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3824310e536af032</td>\n",
       "      <td>1344753412</td>\n",
       "      <td>88</td>\n",
       "      <td>14th_century;Europe;Africa;Atlantic_slave_trad...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>415612e93584d30e</td>\n",
       "      <td>1349298640</td>\n",
       "      <td>138</td>\n",
       "      <td>14th_century;Niger;Nigeria;British_Empire;Slav...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64dd5cd342e3780c</td>\n",
       "      <td>1265613925</td>\n",
       "      <td>37</td>\n",
       "      <td>14th_century;Renaissance;Ancient_Greece;Greece</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>015245d773376aab</td>\n",
       "      <td>1366730828</td>\n",
       "      <td>175</td>\n",
       "      <td>14th_century;Italy;Roman_Catholic_Church;HIV;R...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hashedIpAddress   timestamp  durationInSec  \\\n",
       "0  6a3701d319fc3754  1297740409            166   \n",
       "1  3824310e536af032  1344753412             88   \n",
       "2  415612e93584d30e  1349298640            138   \n",
       "3  64dd5cd342e3780c  1265613925             37   \n",
       "4  015245d773376aab  1366730828            175   \n",
       "\n",
       "                                                path  rating  \n",
       "0  14th_century;15th_century;16th_century;Pacific...     NaN  \n",
       "1  14th_century;Europe;Africa;Atlantic_slave_trad...     3.0  \n",
       "2  14th_century;Niger;Nigeria;British_Empire;Slav...     NaN  \n",
       "3     14th_century;Renaissance;Ancient_Greece;Greece     NaN  \n",
       "4  14th_century;Italy;Roman_Catholic_Church;HIV;R...     3.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finished_paths.info()\n",
    "display(finished_paths.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24875 entries, 0 to 24874\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   hashedIpAddress  24875 non-null  object\n",
      " 1   timestamp        24875 non-null  int64 \n",
      " 2   durationInSec    24875 non-null  int64 \n",
      " 3   path             24875 non-null  object\n",
      " 4   target           24875 non-null  object\n",
      " 5   type             24875 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashedIpAddress</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>durationInSec</th>\n",
       "      <th>path</th>\n",
       "      <th>target</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2426091a53125110</td>\n",
       "      <td>1297054935</td>\n",
       "      <td>1804</td>\n",
       "      <td>Obi-Wan_Kenobi</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>timeout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26141fd878806294</td>\n",
       "      <td>1297055651</td>\n",
       "      <td>1805</td>\n",
       "      <td>Julius_Caesar</td>\n",
       "      <td>Caracas</td>\n",
       "      <td>timeout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2b015fb8181c48f2</td>\n",
       "      <td>1297090819</td>\n",
       "      <td>1818</td>\n",
       "      <td>Malawi;Democracy;Alexander_the_Great</td>\n",
       "      <td>First_Crusade</td>\n",
       "      <td>timeout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53a53bc244e08a6a</td>\n",
       "      <td>1297094761</td>\n",
       "      <td>49</td>\n",
       "      <td>Paraguay</td>\n",
       "      <td>Mount_St._Helens</td>\n",
       "      <td>restart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53a53bc244e08a6a</td>\n",
       "      <td>1297099105</td>\n",
       "      <td>1808</td>\n",
       "      <td>Paraguay;Bolivia</td>\n",
       "      <td>Mount_St._Helens</td>\n",
       "      <td>timeout</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hashedIpAddress   timestamp  durationInSec  \\\n",
       "0  2426091a53125110  1297054935           1804   \n",
       "1  26141fd878806294  1297055651           1805   \n",
       "2  2b015fb8181c48f2  1297090819           1818   \n",
       "3  53a53bc244e08a6a  1297094761             49   \n",
       "4  53a53bc244e08a6a  1297099105           1808   \n",
       "\n",
       "                                   path            target     type  \n",
       "0                        Obi-Wan_Kenobi         Microsoft  timeout  \n",
       "1                         Julius_Caesar           Caracas  timeout  \n",
       "2  Malawi;Democracy;Alexander_the_Great     First_Crusade  timeout  \n",
       "3                              Paraguay  Mount_St._Helens  restart  \n",
       "4                      Paraguay;Bolivia  Mount_St._Helens  timeout  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unfinished_paths.info()\n",
    "display(unfinished_paths.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119879 entries, 0 to 119878\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   start   119879 non-null  object\n",
      " 1   end     119879 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>%C3%81ed%C3%A1n_mac_Gabr%C3%A1in</td>\n",
       "      <td>Great_Britain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>%C3%81ed%C3%A1n_mac_Gabr%C3%A1in</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>%C3%81ed%C3%A1n_mac_Gabr%C3%A1in</td>\n",
       "      <td>Isle_of_Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>%C3%81ed%C3%A1n_mac_Gabr%C3%A1in</td>\n",
       "      <td>Monarchy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>%C3%81ed%C3%A1n_mac_Gabr%C3%A1in</td>\n",
       "      <td>Orkney</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              start            end\n",
       "0  %C3%81ed%C3%A1n_mac_Gabr%C3%A1in  Great_Britain\n",
       "1  %C3%81ed%C3%A1n_mac_Gabr%C3%A1in        Ireland\n",
       "2  %C3%81ed%C3%A1n_mac_Gabr%C3%A1in    Isle_of_Man\n",
       "3  %C3%81ed%C3%A1n_mac_Gabr%C3%A1in       Monarchy\n",
       "4  %C3%81ed%C3%A1n_mac_Gabr%C3%A1in         Orkney"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.info()\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4604 entries, 0 to 4603\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   article  4604 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 36.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>%C3%81ed%C3%A1n_mac_Gabr%C3%A1in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>%C3%85land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>%C3%89douard_Manet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>%C3%89ire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>%C3%93engus_I_of_the_Picts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            article\n",
       "0  %C3%81ed%C3%A1n_mac_Gabr%C3%A1in\n",
       "1                        %C3%85land\n",
       "2                %C3%89douard_Manet\n",
       "3                         %C3%89ire\n",
       "4        %C3%93engus_I_of_the_Picts"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.info()\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>%C3%81ed%C3%A1n_mac_Gabr%C3%A1in</td>\n",
       "      <td>subject.History.British_History.British_Histor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>%C3%81ed%C3%A1n_mac_Gabr%C3%A1in</td>\n",
       "      <td>subject.People.Historical_figures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>%C3%85land</td>\n",
       "      <td>subject.Countries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>%C3%85land</td>\n",
       "      <td>subject.Geography.European_Geography.European_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>%C3%89douard_Manet</td>\n",
       "      <td>subject.People.Artists</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            article  \\\n",
       "0  %C3%81ed%C3%A1n_mac_Gabr%C3%A1in   \n",
       "1  %C3%81ed%C3%A1n_mac_Gabr%C3%A1in   \n",
       "2                        %C3%85land   \n",
       "3                        %C3%85land   \n",
       "4                %C3%89douard_Manet   \n",
       "\n",
       "                                            category  \n",
       "0  subject.History.British_History.British_Histor...  \n",
       "1                  subject.People.Historical_figures  \n",
       "2                                  subject.Countries  \n",
       "3  subject.Geography.European_Geography.European_...  \n",
       "4                             subject.People.Artists  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories.head()\n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0, 255, 255, ...,   4,   4,   2],\n",
       "       [255,   0, 255, ...,   3,   3,   3],\n",
       "       [255, 255,   0, ...,   3,   3,   3],\n",
       "       ...,\n",
       "       [255, 255, 255, ...,   0,   3,   3],\n",
       "       [255, 255, 255, ...,   4,   0,   3],\n",
       "       [255, 255, 255, ...,   3,   3,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shortest paths corresponds to numpy matrix, where 255 signifies no path (underscore in the .txt file), the diagonal is zero\n",
    "# the row index is the zero-based index corresponding to the index in the articles dataframe, same for the columns (target article)\n",
    "print((np.diag(shortest_paths)==0).all())\n",
    "shortest_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up edge list\n",
    "display(edges.head())\n",
    "edges[\"start\"] = edges.start.apply(urllib.parse.unquote)\n",
    "edges[\"end\"] = edges.end.apply(urllib.parse.unquote)\n",
    "display(edges.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format datetime as datetime object\n",
    "finished_paths[\"datetime\"] = finished_paths.timestamp.apply(datetime.datetime.fromtimestamp)\n",
    "unfinished_paths[\"datetime\"] = unfinished_paths.timestamp.apply(datetime.datetime.fromtimestamp)\n",
    "display(unfinished_paths.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up url encoding for articles\n",
    "display(articles.head())\n",
    "articles[\"article\"] = articles.article.apply(urllib.parse.unquote)\n",
    "display(articles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up url encoding for categories\n",
    "display(categories.head())\n",
    "categories[\"article\"] = categories.article.apply(urllib.parse.unquote)\n",
    "display(categories.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge articles and categories\n",
    "articles_categories = pd.merge(articles, categories, how=\"left\", on=\"article\")\n",
    "display(articles_categories.head())\n",
    "# 6 articles without category!\n",
    "print(\"Merge introduced {} NAs in category columns:\".format(articles_categories.category.isna().sum()))\n",
    "articles_categories[articles_categories.category.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert paths to a readable format (lists)\n",
    "\n",
    "finished_paths_readable = finished_paths.copy()\n",
    "finished_paths_readable[\"readable_path\"] = finished_paths_readable[\"path\"].apply(lambda x: x.split(\";\"))\n",
    "finished_paths_readable[\"readable_path\"] = finished_paths_readable[\"readable_path\"].apply(lambda x: [urllib.parse.unquote(y) for y in x])\n",
    "\n",
    "unfinished_paths_readable = unfinished_paths.copy()\n",
    "unfinished_paths_readable[\"readable_path\"] = unfinished_paths_readable[\"path\"].apply(lambda x: x.split(\";\"))\n",
    "unfinished_paths_readable[\"readable_path\"] = unfinished_paths_readable[\"readable_path\"].apply(lambda x: [urllib.parse.unquote(y) for y in x])\n",
    "unfinished_paths_readable[\"target\"] = unfinished_paths_readable[\"target\"].apply(urllib.parse.unquote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to get all links between articles\n",
    "from itertools import tee\n",
    "def pairwise(iterable):\n",
    "    # from python docs - will be introduced in version 3.10\n",
    "    # pairwise('ABCDEFG') --> AB BC CD DE EF FG\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "\n",
    "def get_all_links(df, path_colname=\"path\"):\n",
    "    edge_counter = {}\n",
    "    for _, row in df.iterrows():\n",
    "        links = row['path'].split(';')\n",
    "        \n",
    "        edges = list(pairwise(links))\n",
    "\n",
    "        for edge in edges:\n",
    "            if edge in edge_counter:\n",
    "                edge_counter[edge] += 1\n",
    "            else:\n",
    "                edge_counter[edge] = 1\n",
    "\n",
    "    out = pd.Series(edge_counter).reset_index()\n",
    "    out.columns = [\"source\", \"target\", \"weight\"]\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all finished links\n",
    "finished_links = get_all_links(finished_paths)\n",
    "finished_links.sort_values(by=\"weight\", ascending=False) # TODO: what is up with these <<< signs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unfinished links\n",
    "unfinished_links = get_all_links(unfinished_paths)\n",
    "unfinished_links.sort_values(by=\"weight\", ascending=False) # TODO: what is up with these <<< signs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create newtorkx graph from finished paths\n",
    "finished_graph = nx.from_pandas_edgelist(finished_links,source=\"source\", target=\"target\", edge_attr=\"weight\")\n",
    "hist = nx.degree_histogram(finished_graph)\n",
    "plt.bar(range(len(hist)), hist)\n",
    "pd.Series(hist).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create newtorkx graph from unfinished paths\n",
    "unfinished_graph = nx.from_pandas_edgelist(unfinished_links,source=\"source\", target=\"target\", edge_attr=\"weight\")\n",
    "hist = nx.degree_histogram(unfinished_graph)\n",
    "plt.bar(range(len(hist)), hist)\n",
    "pd.Series(hist).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Data Exploration\n",
    "Explore distribution of all relevant variables, analyze and potentially fill missing values, sÃ®mple summary stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Path lengths across finished and unfinished paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of path lengths disaggregated across finished and unfinished\n",
    "unfinished_paths[\"path_length\"] = unfinished_paths.path.apply(lambda el: len(el.split(\";\")))\n",
    "finished_paths[\"path_length\"] = finished_paths.path.apply(lambda el: len(el.split(\";\")))\n",
    "\n",
    "print(\"Finished Paths: Length\")\n",
    "display(finished_paths[\"path_length\"].describe())\n",
    "display(finished_paths.path_length.value_counts())\n",
    "\n",
    "print(\"Unfinished Paths: Length\")\n",
    "display(unfinished_paths[\"path_length\"].describe())\n",
    "unfinished_paths.path_length.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot of path lengths\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 4), sharey=True)\n",
    "\n",
    "sns.histplot(data=finished_paths, x=\"path_length\", ax=axes[0])\n",
    "axes[0].set_title(\"Finished Paths\")\n",
    "sns.histplot(data=unfinished_paths, x=\"path_length\", ax=axes[1], hue=\"type\")\n",
    "axes[1].set_title(\"Uninished Paths\")\n",
    "\n",
    "# --> highly skewed and many unlikely outcomes (e.g. unfinished paths path length = 1, did they really give up? or not play at all?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot comparing path lengths after cleaning up (e.g., kicking out top 10 percentiles, log transforms etc.) to better understand what is going on\n",
    "\n",
    "# make plot of path lengths\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(14, 4), sharey=True)\n",
    "threshold = 30\n",
    "\n",
    "\n",
    "sns.histplot(x=finished_paths.path_length[finished_paths.path_length < threshold], ax=axes[0], discrete=True)\n",
    "axes[0].set_title(\"Finished Paths\")\n",
    "\n",
    "unfinished_clean = unfinished_paths[(unfinished_paths.path_length < threshold) & (unfinished_paths.type == \"restart\")]\n",
    "sns.histplot(data=unfinished_clean, x=\"path_length\", ax=axes[1], discrete=True,)\n",
    "axes[1].set_title(\"Uninished Paths - Restart\")\n",
    "\n",
    "unfinished_clean = unfinished_paths[(unfinished_paths.path_length < threshold) & (unfinished_paths.type == \"timeout\")]\n",
    "sns.histplot(data=unfinished_clean, x=\"path_length\", ax=axes[2], discrete=True,)\n",
    "axes[2].set_title(\"Uninished Paths - Timeout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore categories in the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing which categories are most represented in articles\n",
    "\n",
    "broad_categories = categories.copy()\n",
    "broad_categories[\"broad_category\"] = broad_categories[\"category\"].apply(lambda x: x.split(\".\")[1])\n",
    "\n",
    "count_articles = broad_categories.groupby(\"broad_category\").size()\n",
    "\n",
    "print(\"Below shows how many articles each of the broad categories are represented by\")\n",
    "display(count_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries for easy discovery of what categories an article belongs to\n",
    "article_to_category = {}\n",
    "article_to_broad_category = {}\n",
    "for i in range(len(broad_categories)):\n",
    "    if broad_categories.iloc[i][\"article\"] in article_to_category:\n",
    "        article_to_category[broad_categories.iloc[i][\"article\"]].append(broad_categories.iloc[i][\"category\"])\n",
    "        article_to_broad_category[broad_categories.iloc[i][\"article\"]].append(broad_categories.iloc[i][\"broad_category\"])\n",
    "    else:\n",
    "        article_to_category[broad_categories.iloc[i][\"article\"]] = [broad_categories.iloc[i][\"category\"]]\n",
    "        article_to_broad_category[broad_categories.iloc[i][\"article\"]] = [broad_categories.iloc[i][\"broad_category\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times each category has occured as a target in the finished paths\n",
    "\n",
    "# NOTE THAT SOME ARTICLES ARE REPRESENTED BY MULTIPLE CATEGORIES AND ARE COUNTED TWICE\n",
    "all_target_broad_categories_f = [article_to_broad_category[target] for target in [path[-1] for path in finished_paths_readable[\"readable_path\"]] if target in article_to_broad_category]\n",
    "all_target_broad_categories_f = [item for sublist in all_target_broad_categories_f for item in sublist]\n",
    "count_cats_finished_target = Counter(all_target_broad_categories_f)\n",
    "display(count_cats_finished_target)\n",
    "\n",
    "ax = plt.pie(count_cats_finished_target.values(), labels = count_cats_finished_target.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times each category has occured as a target in the finished paths\n",
    "\n",
    "# NOTE THAT SOME ARTICLES ARE REPRESENTED BY MULTIPLE CATEGORIES AND ARE COUNTED TWICE\n",
    "all_target_broad_categories_u = [article_to_broad_category[target] for target in unfinished_paths_readable[\"target\"] if target in article_to_broad_category]\n",
    "all_target_broad_categories_u = [item for sublist in all_target_broad_categories_u for item in sublist]\n",
    "count_cats_unfinished_target = Counter(all_target_broad_categories_u)\n",
    "count_cats_unfinished_target\n",
    "\n",
    "display(count_cats_unfinished_target)\n",
    "\n",
    "ax = plt.pie(count_cats_unfinished_target.values(), labels = count_cats_unfinished_target.keys())\n",
    "plt.show()\n",
    "\n",
    "# There are certain categories that show up more or less here proportionally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which countries are targets in finished paths\n",
    "\n",
    "country_targets_f = [target for target in [path[-1] for path in finished_paths_readable[\"readable_path\"]] if target in article_to_broad_category and \"Countries\" in article_to_broad_category[target]]\n",
    "count_countries_finished_target = Counter(country_targets_f)\n",
    "display(count_countries_finished_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which countries are targets in unfinished paths\n",
    "\n",
    "country_targets_u = [target for target in unfinished_paths_readable[\"target\"] if target in article_to_broad_category and \"Countries\" in article_to_broad_category[target]]\n",
    "count_countries_unfinished_target = Counter(country_targets_u)\n",
    "display(count_countries_unfinished_target)\n",
    "\n",
    "# There are certainly some trends here. Haiti, Samoa, and the Gaza Strip, for example, are over-represented in the unfinished paths\n",
    "# when compared to the finished paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In fact we can see that there are some countries that occured as a target more in unfinished paths than in finished paths\n",
    "count_countries_unfinished_target - count_countries_finished_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_country_counts = count_countries_unfinished_target + count_countries_finished_target\n",
    "country_percent_in_unfinished = total_country_counts.copy()\n",
    "country_percent_in_finished = total_country_counts.copy()\n",
    "\n",
    "for item, count in country_percent_in_unfinished.items():\n",
    "    country_percent_in_unfinished[item] = count_countries_unfinished_target[item] / total_country_counts[item]\n",
    "\n",
    "for item, count in country_percent_in_finished.items():\n",
    "    country_percent_in_finished[item] = count_countries_finished_target[item] / total_country_counts[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_percent_in_unfinished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_percent_in_finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring subject strength between connected article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_article_df = edges.copy()\n",
    "\n",
    "def add_categories(row, column):\n",
    "    article_name = row[column]\n",
    "    if article_name in article_to_broad_category:\n",
    "        return article_to_broad_category[article_name]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "edge_article_df['start_categories'] = edge_article_df.apply(add_categories, args=(\"start\",), axis=1)\n",
    "edge_article_df['end_categories'] = edge_article_df.apply(add_categories, args=(\"end\",), axis=1)\n",
    "display(edge_article_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.DiGraph()\n",
    "\n",
    "for index, row in edge_article_df.iterrows():\n",
    "    start_article = row['start'][0]\n",
    "    for start_category in row['start_categories']:\n",
    "      graph.add_node(start_category)\n",
    "      for end_category in row['end_categories']:\n",
    "        graph.add_node(end_category)\n",
    "\n",
    "        if graph.has_edge(start_category, end_category):\n",
    "          graph[start_category][end_category]['weight'] += 1\n",
    "        else:\n",
    "          graph.add_edge(start_category, end_category, weight=1)\n",
    "\n",
    "edge_weights = [graph[u][v]['weight'] for u, v in graph.edges()]\n",
    "max_edge_weight = max(edge_weights)\n",
    "min_edge_weight = min(edge_weights)\n",
    "normalized_edge_weights = [(weight - min_edge_weight) / (max_edge_weight - min_edge_weight) for weight in edge_weights]\n",
    "edge_widths = [weight * 5 for weight in normalized_edge_weights]\n",
    "\n",
    "figure = nx.shell_layout(graph)\n",
    "plt.figure(figsize=(8, 8))\n",
    "nx.draw(graph, figure, with_labels=True, width=edge_widths, edge_color='gray', arrows=True)\n",
    "plt.title(\"Article Connections Based on Subjects (Normalized and Scaled Edges)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics:\n",
    "* Total word count: To understand the length of the article.\n",
    "* Non stopword frequency: To identify words that contribute to the content's meaning.\n",
    "* Stopword frequency: To identify common words that may not contribute to the content's meaning.\n",
    "* Average word length: To assess the complexity of the language used.\n",
    "* Average sentence length: Longer or more complex sentences (based on characters) may contribute to frustration.\n",
    "* Number of paragraphs: To see if the article's structure plays a role in people giving up.\n",
    "* Keyword frequency: To identify the most common keywords to understand the article's focus.\n",
    "* Readability: Ease of reading the article (metric: Flesch Reading Ease Score) Link: https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests\n",
    "\n",
    "TODO:\n",
    "* Compute article embedding\n",
    "* Sentiment analysis (people might dislike certain topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proprocess_article(article_text):\n",
    "    preprocessed_text = article_text\n",
    "    preprocessed_text = preprocessed_text.lower()\n",
    "    preprocessed_text = preprocessed_text.replace(\"\\n   \", \" \") # As the articles are not continuous sentences\n",
    "    return preprocessed_text\n",
    "\n",
    "def calculate_article_metrics(article_text):\n",
    "    preprocessed_text = proprocess_article(article_text)\n",
    "\n",
    "    words = word_tokenize(preprocessed_text)\n",
    "    sentences = sent_tokenize(preprocessed_text)\n",
    "\n",
    "    # Calculate total word count\n",
    "    total_word_count = len(words)\n",
    "\n",
    "    # Calculate stopword frequency\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    stopwords_count = sum(1 for word in words if word.lower() in stop_words)\n",
    "\n",
    "    # Calculate average word length\n",
    "    average_word_length = sum(len(word) for word in words) / total_word_count\n",
    "\n",
    "    # Calculate average sentence length\n",
    "    average_sentence_length = sum(len(sentence) for sentence in sentences) / len(sentences)\n",
    "\n",
    "    # Calculate number of paragraphs (assume every new line \\n is paragraph)\n",
    "    paragraphs_count = preprocessed_text.count('\\n') + 1 # Count last paragraph\n",
    "\n",
    "    # Calculate keyword frequency\n",
    "    word_freq = nltk.FreqDist(words)\n",
    "    most_common_words = word_freq.most_common(10)  # Parameter to adjust\n",
    "\n",
    "    # Calculate readability (Flesch Reading Ease Score) - 100: Easy to read, 0: Very confusing\n",
    "    readability = textstat.flesch_reading_ease(preprocessed_text)\n",
    "\n",
    "    return {\n",
    "        \"word_count\": total_word_count,\n",
    "        \"non_stopword_count\": total_word_count - stopwords_count,\n",
    "        \"stopword_count\": stopwords_count,\n",
    "        \"avg_word_length\": average_word_length,\n",
    "        \"avg_sent_length\": average_sentence_length,\n",
    "        \"paragraph_count\": paragraphs_count,\n",
    "        \"common_words\": most_common_words,\n",
    "        \"readability_score\": readability,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(DATA_PATH, \"plaintext_articles\")\n",
    "if os.path.exists(path) and os.path.isdir(path):\n",
    "\n",
    "  article_metrics = pd.DataFrame(columns=[\"file_name\", \"word_count\", \"non_stopword_count\", \"stopword_count\", \"avg_word_length\", \"avg_sent_length\", \"paragraph_count\", \"common_words\", \"readability_score\"])\n",
    "\n",
    "  #Testing: for file_name in [\"%C3%81ed%C3%A1n_mac_Gabr%C3%A1in.txt\"]:\n",
    "  for file_name in os.listdir(path):\n",
    "    file_path = os.path.join(path, file_name)\n",
    "    \n",
    "    if os.path.isfile(file_path):\n",
    "      readable_file_name = urllib.parse.unquote(file_name)\n",
    "      \n",
    "      with open(file_path, \"r\", encoding=\"utf-8\") as article:\n",
    "        metrics = calculate_article_metrics(article.read())\n",
    "\n",
    "        metrics[\"file_name\"] = readable_file_name\n",
    "        article_metrics.loc[len(article_metrics)] = metrics\n",
    "else:\n",
    "  raise FileNotFoundError(\"The specified folder path does not exist or is not a directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: percentage wise, from start to end, what categories are used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze links to targets in finished vs unfinished articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished_paths_target_links = finished_paths_readable.copy()\n",
    "unfinished_paths_target_links = unfinished_paths_readable.copy()\n",
    "finished_paths_target_links[\"links_to_target\"] = finished_paths_target_links[\"readable_path\"].apply(lambda x: len(edges.loc[edges[\"end\"] == x[-1]]))\n",
    "unfinished_paths_target_links[\"links_to_target\"] = unfinished_paths_target_links[\"target\"].apply(lambda x: len(edges.loc[edges[\"end\"] == x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing mean number of links to the targets in the finished and unfinished paths.\n",
    "print(f\"The targets that were reached had {finished_paths_target_links['links_to_target'].mean()} links on average pointing to them.\")\n",
    "print(f\"The targets that were not reached had {unfinished_paths_target_links['links_to_target'].mean()} links on average pointing to them.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conducting a t-test\n",
    "stats.ttest_ind(finished_paths_target_links[\"links_to_target\"], unfinished_paths_target_links[\"links_to_target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value of a t-test between the number of links pointing to the targets of finished and unfinished paths is 0.0. This means we reject the null hypothesis that the number of links pointing to the targets are statistically the same at the 5% level of significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse possible shortest path distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished_paths_shortest_possible = finished_paths_readable.copy()\n",
    "unfinished_paths_shortest_possible = unfinished_paths_readable.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished_paths_shortest_possible[\"shortest_path_length\"] = finished_paths_shortest_possible[\"readable_path\"].apply(lambda x: shortest_paths[articles.loc[articles['article'] == x[0]].index[0]][articles.loc[articles['article'] == x[-1]].index[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE IMPORTANT: THERE ARE TYPOS\n",
    "\n",
    "\n",
    "Eg. At index 141 in unfinished paths, the target is written as \"Long_peper\", when it should be \"Long_pepper\"\n",
    "\n",
    "Overall, 28 times an issue arises in unfinished paths. Doesn't seem to be an issue in finished paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_unfinished = []\n",
    "not_found = 0\n",
    "for i in range(len(unfinished_paths_shortest_possible)):\n",
    "    source = articles.loc[articles['article'] == unfinished_paths_shortest_possible.iloc[i][\"readable_path\"][0]]\n",
    "    target = articles.loc[articles['article'] == unfinished_paths_shortest_possible.iloc[i][\"target\"]]\n",
    "    if len(source) != 0 and len(target) != 0:\n",
    "        index_source = source.index[0]\n",
    "        index_target = target.index[0]\n",
    "        shortest_unfinished.append(int(shortest_paths[index_source][index_target]))\n",
    "    else:\n",
    "        shortest_unfinished.append(None)\n",
    "        not_found+=1\n",
    "\n",
    "unfinished_paths_shortest_possible[\"shortest_path_length\"] = shortest_unfinished\n",
    "print(f\"{not_found} shortest paths not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_finished = []\n",
    "not_found2 = 0\n",
    "for i in range(len(finished_paths_shortest_possible)):\n",
    "    source = articles.loc[articles['article'] == finished_paths_shortest_possible.iloc[i][\"readable_path\"][0]]\n",
    "    target = articles.loc[articles['article'] == finished_paths_shortest_possible.iloc[i][\"readable_path\"][-1]]\n",
    "    if len(source) != 0 and len(target) != 0:\n",
    "        index_source = source.index[0]\n",
    "        index_target = target.index[0]\n",
    "        shortest_finished.append(int(shortest_paths[index_source][index_target]))\n",
    "    else:\n",
    "        shortest_finished.append(None)\n",
    "        not_found2+=1\n",
    "\n",
    "print(f\"{not_found2} shortest paths not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing mean shortest possible paths in the finished and unfinished paths.\n",
    "print(f\"The shortest possible paths were {finished_paths_shortest_possible['shortest_path_length'].mean()} long on average in the finished paths.\")\n",
    "print(f\"The shortest possible paths were {unfinished_paths_shortest_possible['shortest_path_length'].mean()} long on average in the unfinished paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(finished_paths_shortest_possible['shortest_path_length'], unfinished_paths_shortest_possible['shortest_path_length'], nan_policy=\"omit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t test shows that indeed this is a significant difference. Unfinished paths are thus inherently more difficult to get to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an interesting situation. The past two analyses show that the targets are more difficult to get to in the unfinished paths, due to the fewer links that point at them and the larger value of the possible shortest path to them.\n",
    "\n",
    "A challenge for us may be to try to isolate whether the difference between whether a path is finished or not can be fully explained by more objective factors like this, or if there is a human component that we can isolate as well. Eg, are some categories actually more difficult to get to, or do the differences in the target category distributions in the finished and unfinished paths arise because some categories may be more likely to have longer possible shortest paths to them or have fewer links pointing at them?\n",
    "\n",
    "We should explore these ideas\n",
    "\n",
    "TODO: Start working on the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Networkx graph objects \n",
    "degreehistograms, etc. etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next Idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Specific to Idea 1\n",
    "Explore specific questions as noted in notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate some summary stats on the wikipedia articles (length, number of hyperlinks etc. from the additional data given in teh task (not laoded yet)) to check some of our hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Specific to Idea 2\n",
    "Explore specific questions as noted in notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Specific to Idea 3\n",
    "Explore specific questions as noted in notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Specific to Idea 4\n",
    "Explore specific questions as noted in notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Specific to Idea 5\n",
    "Explore specific questions as noted in notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
