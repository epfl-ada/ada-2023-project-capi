{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA CAPI Notebook for Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats \n",
    "\n",
    "# Helper functions from utils folder\n",
    "from utils.analysis import t_test_article_metrics, visualize_article_connections_per_category\n",
    "from utils.preprocessing import get_all_links, merge_articles_categories\n",
    "\n",
    "# Formatting libraries\n",
    "import urllib\n",
    "import datetime as datetime\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Imports to perform article analysis\n",
    "import textstat\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt') # Punkt tokenizer\n",
    "nltk.download('stopwords') # Commong stopwords\n",
    "\n",
    "# Load config and extract variables\n",
    "import config\n",
    "DATA_PATH = config.PATH_TO_DATA\n",
    "PATH_GRAPGH_FOLDER = \"wikispeedia_paths-and-graph\"\n",
    "ARTICLE_FOLDER = \"plaintext_articles\"\n",
    "GENERATED_METRICS = \"generated_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preparing the Data\n",
    "Load and clean up the paths, load into weighted graph structure etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in all data (except wikipedia articles)\n",
    "finished_paths = pd.read_csv(os.path.join(DATA_PATH, PATH_GRAPGH_FOLDER, \"paths_finished.tsv\"), sep='\\t', skiprows=15, names=[\"hashedIpAddress\", \"timestamp\", \"durationInSec\", \"path\", \"rating\"])\n",
    "unfinished_paths = pd.read_csv(os.path.join(DATA_PATH, PATH_GRAPGH_FOLDER, \"paths_unfinished.tsv\"), sep='\\t', skiprows=16, names=[\"hashedIpAddress\", \"timestamp\", \"durationInSec\", \"path\", \"target\", \"type\"])\n",
    "edges = pd.read_csv(os.path.join(DATA_PATH, PATH_GRAPGH_FOLDER, \"links.tsv\"), sep='\\t', skiprows=15, names=[\"start\", \"end\"], encoding=\"utf-8\")\n",
    "articles = pd.read_csv(os.path.join(DATA_PATH, PATH_GRAPGH_FOLDER, \"articles.tsv\"), sep='\\t', skiprows=12, names=[\"article\"], encoding=\"utf-8\")\n",
    "categories = pd.read_csv(os.path.join(DATA_PATH, PATH_GRAPGH_FOLDER, \"categories.tsv\"), sep='\\t', skiprows=13, names=[\"article\", \"category\"], encoding=\"utf-8\")\n",
    "shortest_paths = np.genfromtxt(os.path.join(DATA_PATH, PATH_GRAPGH_FOLDER, \"shortest-path-distance-matrix.txt\"), delimiter=1, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(finished_paths.info())\n",
    "display(finished_paths.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(unfinished_paths.info())\n",
    "display(unfinished_paths.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(edges.info())\n",
    "display(edges.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(articles.info())\n",
    "display(articles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(categories.head())\n",
    "display(categories.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortest paths corresponds to numpy matrix, where 255 signifies no path (underscore in the .txt file), the diagonal is zero\n",
    "# the row index is the zero-based index corresponding to the index in the articles dataframe, same for the columns (target article)\n",
    "print((np.diag(shortest_paths)==0).all())\n",
    "shortest_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up edge list\n",
    "display(edges.head())\n",
    "edges[\"start\"] = edges.start.apply(urllib.parse.unquote)\n",
    "edges[\"end\"] = edges.end.apply(urllib.parse.unquote)\n",
    "display(edges.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format datetime as datetime object\n",
    "display(articles.head())\n",
    "finished_paths[\"datetime\"] = finished_paths.timestamp.apply(datetime.datetime.fromtimestamp)\n",
    "unfinished_paths[\"datetime\"] = unfinished_paths.timestamp.apply(datetime.datetime.fromtimestamp)\n",
    "display(unfinished_paths.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up url encoding for articles\n",
    "display(articles.head())\n",
    "articles[\"article\"] = articles.article.apply(urllib.parse.unquote)\n",
    "display(articles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up url encoding for categories\n",
    "display(categories.head())\n",
    "categories[\"article\"] = categories.article.apply(urllib.parse.unquote)\n",
    "display(categories.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify broad categories of articles\n",
    "display(categories.head())\n",
    "categories[\"broad_category\"] = categories[\"category\"].apply(lambda x: x.split(\".\")[1])\n",
    "display(categories.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge articles and categories\n",
    "articles_categories = pd.merge(articles, categories, how=\"left\", on=\"article\")\n",
    "display(articles_categories.head())\n",
    "# 6 articles without category!\n",
    "print(\"Merge introduced {} NAs in category columns:\".format(articles_categories.category.isna().sum()))\n",
    "articles_categories[articles_categories.category.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert paths to a readable format (lists)\n",
    "finished_paths[\"path\"] = finished_paths[\"path\"].apply(lambda x: x.split(\";\"))\n",
    "finished_paths[\"path\"] = finished_paths[\"path\"].apply(lambda x: [urllib.parse.unquote(y) for y in x])\n",
    "\n",
    "unfinished_paths[\"path\"] = unfinished_paths[\"path\"].apply(lambda x: x.split(\";\"))\n",
    "unfinished_paths[\"path\"] = unfinished_paths[\"path\"].apply(lambda x: [urllib.parse.unquote(y) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add start and target articles of path\n",
    "finished_paths[\"start\"] = [path[0] for path in finished_paths[\"path\"]]\n",
    "finished_paths[\"target\"] = [path[-1] for path in finished_paths[\"path\"]]\n",
    "\n",
    "unfinished_paths[\"start\"] = [path[0] for path in unfinished_paths[\"path\"]]\n",
    "unfinished_paths[\"target\"] = unfinished_paths[\"target\"].apply(urllib.parse.unquote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all finished links\n",
    "finished_links = get_all_links(finished_paths)\n",
    "finished_links.sort_values(by=\"weight\", ascending=False) # TODO: what is up with these <<< signs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unfinished links\n",
    "unfinished_links = get_all_links(unfinished_paths)\n",
    "unfinished_links.sort_values(by=\"weight\", ascending=False) # TODO: what is up with these <<< signs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create newtorkx graph from finished paths\n",
    "finished_graph = nx.from_pandas_edgelist(finished_links,source=\"source\", target=\"target\", edge_attr=\"weight\")\n",
    "hist = nx.degree_histogram(finished_graph)\n",
    "plt.bar(range(len(hist)), hist)\n",
    "pd.Series(hist).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create newtorkx graph from unfinished paths\n",
    "unfinished_graph = nx.from_pandas_edgelist(unfinished_links,source=\"source\", target=\"target\", edge_attr=\"weight\")\n",
    "hist = nx.degree_histogram(unfinished_graph)\n",
    "plt.bar(range(len(hist)), hist)\n",
    "pd.Series(hist).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Article data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metrics to be extracted from articles\n",
    "\n",
    "* Total word count: To understand the length of the article.\n",
    "* Non stopword frequency: To identify words that contribute to the content's meaning.\n",
    "* Stopword frequency: To identify common words that may not contribute to the content's meaning.\n",
    "* Average word length: To assess the complexity of the language used.\n",
    "* Average sentence length: Longer or more complex sentences (based on characters) may contribute to frustration.\n",
    "* Number of paragraphs: To see if the article's structure plays a role in people giving up.\n",
    "* Keyword frequency: To identify the most common keywords to understand the article's focus.\n",
    "* Readability: Ease of reading the article (metric: Flesch Reading Ease Score) Link: https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proprocess_article(article_text):\n",
    "    preprocessed_text = article_text\n",
    "    preprocessed_text = preprocessed_text.lower()\n",
    "    preprocessed_text = preprocessed_text.replace(\"\\n   \", \" \") # As the articles are not continuous sentences\n",
    "    return preprocessed_text\n",
    "\n",
    "def calculate_article_metrics(article_text):\n",
    "    preprocessed_text = proprocess_article(article_text)\n",
    "\n",
    "    words = word_tokenize(preprocessed_text)\n",
    "    sentences = sent_tokenize(preprocessed_text)\n",
    "\n",
    "    # Calculate total word count\n",
    "    total_word_count = len(words)\n",
    "\n",
    "    # Calculate stopword frequency\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    stopwords_count = 0\n",
    "    unique_words = []\n",
    "    for word in words:\n",
    "        if word.isalpha() and word.lower() in stop_words:\n",
    "            stopwords_count +=1\n",
    "        if word.isalpha() and word.lower() not in stop_words:\n",
    "            unique_words.append(word.lower())\n",
    "\n",
    "    # Calculate average word length\n",
    "    average_word_length = sum(len(word) for word in words) / total_word_count\n",
    "\n",
    "    # Calculate average sentence length\n",
    "    average_sentence_length = sum(len(sentence) for sentence in sentences) / len(sentences)\n",
    "\n",
    "    # Calculate number of paragraphs (assume every new line \\n is paragraph)\n",
    "    paragraphs_count = preprocessed_text.count('\\n') + 1 # Count last paragraph\n",
    "\n",
    "    # Calculate keyword frequency\n",
    "    word_freq = nltk.FreqDist(unique_words)\n",
    "    most_common_words = word_freq.most_common(10)  # Parameter to adjust\n",
    "\n",
    "    # Calculate readability (Flesch Reading Ease Score) - 100: Easy to read, 0: Very confusing\n",
    "    readability = textstat.flesch_reading_ease(preprocessed_text)\n",
    "\n",
    "    return {\n",
    "        \"word_count\": total_word_count,\n",
    "        \"non_stopword_count\": total_word_count - stopwords_count,\n",
    "        \"stopword_count\": stopwords_count,\n",
    "        \"avg_word_length\": average_word_length,\n",
    "        \"avg_sent_length\": average_sentence_length,\n",
    "        \"paragraph_count\": paragraphs_count,\n",
    "        \"common_words\": most_common_words,\n",
    "        \"readability_score\": readability,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the article data\n",
    "To reduce runtime, we compute the article metrics once and then read the generated csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "folder_path = os.path.join(DATA_PATH, ARTICLE_FOLDER)\n",
    "if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "\n",
    "  article_metrics = pd.DataFrame(columns=[\"article\", \"word_count\", \"non_stopword_count\", \"stopword_count\", \"avg_word_length\", \"avg_sent_length\", \"paragraph_count\", \"common_words\", \"readability_score\"])\n",
    "\n",
    "  for file_name in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    if os.path.isfile(file_path):\n",
    "      root, extension = os.path.splitext(file_name)\n",
    "      readable_file_name = urllib.parse.unquote(root)\n",
    "      \n",
    "      with open(file_path, \"r\", encoding=\"utf-8\") as article:\n",
    "        metrics = calculate_article_metrics(article.read())\n",
    "\n",
    "        metrics[\"article\"] = readable_file_name\n",
    "        article_metrics.loc[len(article_metrics)] = metrics\n",
    "else:\n",
    "  raise FileNotFoundError(\"The specified folder path does not exist or is not a directory.\")\n",
    "\n",
    "article_metrics.to_csv(os.path.join(GENERATED_METRICS, \"article_metrics.csv\"), index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_metrics = pd.read_csv(os.path.join(GENERATED_METRICS, \"article_metrics.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(article_metrics.info())\n",
    "display(article_metrics.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Data Exploration\n",
    "Explore distribution of all relevant variables, analyze and potentially fill missing values, sÃ®mple summary stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Path lengths across finished and unfinished paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfinished_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of path lengths disaggregated across finished and unfinished\n",
    "unfinished_paths[\"path_length\"] = unfinished_paths.path.apply(lambda el: len(el))\n",
    "finished_paths[\"path_length\"] = finished_paths.path.apply(lambda el: len(el))\n",
    "\n",
    "print(\"Finished Paths: Length\")\n",
    "display(finished_paths[\"path_length\"].describe())\n",
    "display(finished_paths.path_length.value_counts())\n",
    "\n",
    "print(\"Unfinished Paths: Length\")\n",
    "display(unfinished_paths[\"path_length\"].describe())\n",
    "unfinished_paths.path_length.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot of path lengths\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 4), sharey=True)\n",
    "\n",
    "sns.histplot(data=finished_paths, x=\"path_length\", ax=axes[0])\n",
    "axes[0].set_title(\"Finished Paths\")\n",
    "sns.histplot(data=unfinished_paths, x=\"path_length\", ax=axes[1], hue=\"type\")\n",
    "axes[1].set_title(\"Uninished Paths\")\n",
    "\n",
    "# --> highly skewed and many unlikely outcomes (e.g. unfinished paths path length = 1, did they really give up? or not play at all?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make plot of path lengths\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(14, 4), sharey=True)\n",
    "threshold = 30\n",
    "\n",
    "\n",
    "sns.histplot(x=finished_paths.path_length[finished_paths.path_length < threshold], ax=axes[0], discrete=True)\n",
    "axes[0].set_title(\"Finished Paths\")\n",
    "\n",
    "unfinished_clean = unfinished_paths[(unfinished_paths.path_length < threshold) & (unfinished_paths.type == \"restart\")]\n",
    "sns.histplot(data=unfinished_clean, x=\"path_length\", ax=axes[1], discrete=True,)\n",
    "axes[1].set_title(\"Uninished Paths - Restart\")\n",
    "\n",
    "unfinished_clean = unfinished_paths[(unfinished_paths.path_length < threshold) & (unfinished_paths.type == \"timeout\")]\n",
    "sns.histplot(data=unfinished_clean, x=\"path_length\", ax=axes[2], discrete=True,)\n",
    "axes[2].set_title(\"Uninished Paths - Timeout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore categories in the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing which categories are most represented in articles\n",
    "count_articles = categories.groupby(\"broad_category\").size()\n",
    "\n",
    "print(\"Below shows how many articles each of the broad categories are represented by\")\n",
    "display(count_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries for easy discovery of what categories an article belongs to\n",
    "article_to_category = {}\n",
    "article_to_broad_category = {}\n",
    "for i in range(len(categories)):\n",
    "    if categories.iloc[i][\"article\"] in article_to_category:\n",
    "        article_to_category[categories.iloc[i][\"article\"]].append(categories.iloc[i][\"category\"])\n",
    "        article_to_broad_category[categories.iloc[i][\"article\"]].append(categories.iloc[i][\"broad_category\"])\n",
    "    else:\n",
    "        article_to_category[categories.iloc[i][\"article\"]] = [categories.iloc[i][\"category\"]]\n",
    "        article_to_broad_category[categories.iloc[i][\"article\"]] = [categories.iloc[i][\"broad_category\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times each category has occured as a target in the finished and unfinished paths\n",
    "# NOTE THAT SOME ARTICLES ARE REPRESENTED BY MULTIPLE CATEGORIES AND ARE COUNTED TWICE\n",
    "\n",
    "all_target_broad_categories_f = [\n",
    "  article_to_broad_category[target] for target in finished_paths[\"target\"] if target in article_to_broad_category\n",
    "]\n",
    "all_target_broad_categories_f = [item for sublist in all_target_broad_categories_f for item in sublist]\n",
    "count_cats_finished_target = Counter(all_target_broad_categories_f)\n",
    "keys = list(count_cats_finished_target.keys())\n",
    "keys.sort()\n",
    "sorted_cats_f = {i: count_cats_finished_target[i] for i in keys}\n",
    "#display(sorted_cats_f)\n",
    "\n",
    "all_target_broad_categories_u = [\n",
    "  article_to_broad_category[target] for target in unfinished_paths[\"target\"] if target in article_to_broad_category\n",
    "]\n",
    "all_target_broad_categories_u = [item for sublist in all_target_broad_categories_u for item in sublist]\n",
    "count_cats_unfinished_target = Counter(all_target_broad_categories_u)\n",
    "keys = list(count_cats_unfinished_target.keys())\n",
    "keys.sort()\n",
    "sorted_cats_u = {i: count_cats_unfinished_target[i] for i in keys}\n",
    "#display(sorted_cats_u)\n",
    "\n",
    "ax = plt.barh(list(sorted_cats_f.keys()), sorted_cats_f.values(), label=\"Finished paths\")\n",
    "ax2 = plt.barh(list(sorted_cats_u.keys()), sorted_cats_u.values(), label=\"Unfinished paths\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.title(\"Occurences of categories as targets\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which countries are targets in finished paths\n",
    "country_targets_f = [\n",
    "  target for target in finished_paths[\"target\"] if target in article_to_broad_category and \"Countries\" in article_to_broad_category[target]\n",
    "]\n",
    "count_countries_finished_target = Counter(country_targets_f)\n",
    "display(count_countries_finished_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which countries are targets in unfinished paths\n",
    "\n",
    "country_targets_u = [\n",
    "  target for target in unfinished_paths[\"target\"] if target in article_to_broad_category and \"Countries\" in article_to_broad_category[target]\n",
    "]\n",
    "count_countries_unfinished_target = Counter(country_targets_u)\n",
    "display(count_countries_unfinished_target)\n",
    "\n",
    "# There are certainly some trends here. Haiti, Samoa, and the Gaza Strip, for example, are over-represented in the unfinished paths\n",
    "# when compared to the finished paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In fact we can see that there are some countries that occured as a target more in unfinished paths than in finished paths\n",
    "count_countries_unfinished_target - count_countries_finished_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_country_counts = count_countries_unfinished_target + count_countries_finished_target\n",
    "country_percent_in_unfinished = total_country_counts.copy()\n",
    "country_percent_in_finished = total_country_counts.copy()\n",
    "\n",
    "for item, count in country_percent_in_unfinished.items():\n",
    "    country_percent_in_unfinished[item] = count_countries_unfinished_target[item] / total_country_counts[item]\n",
    "\n",
    "for item, count in country_percent_in_finished.items():\n",
    "    country_percent_in_finished[item] = count_countries_finished_target[item] / total_country_counts[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_percent_in_unfinished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_percent_in_finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore subject strength between connected article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing FINISHED PATHS article connections per category\n",
    "edge_category = merge_articles_categories(edges, [\"start\", \"end\"], articles_categories)\n",
    "visualize_article_connections_per_category(edge_category, \"Article Connections Based on Category (Normalized and Scaled Edges)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing FINISHED PATHS article connections per category\n",
    "finished_paths_categories = merge_articles_categories(finished_paths, [\"start\", \"target\"], articles_categories)\n",
    "visualize_article_connections_per_category(finished_paths_categories, \"Start & Target Article Connections in Finished Path Based on Category (Normalized and Scaled Edges)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing UNFINISHED PATHS article connections per category\n",
    "unfinished_paths_categories = merge_articles_categories(unfinished_paths, [\"start\", \"target\"], articles_categories)\n",
    "visualize_article_connections_per_category(unfinished_paths_categories, \"Start & Target Article Connections in Unfinished Path Based on Category (Normalized and Scaled Edges)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore articles metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_metrics[\"stopword_percentage\"] = article_metrics[\"stopword_count\"] / article_metrics[\"word_count\"]\n",
    "article_metrics[\"non_stopword_percentage\"] = article_metrics[\"non_stopword_count\"] / article_metrics[\"word_count\"]\n",
    "display(article_metrics.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Articles metrics per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge articles with their corresponding categories\n",
    "article_metrics_with_categories = article_metrics.merge(categories, how=\"left\", on=[\"article\"])\n",
    "display(article_metrics_with_categories.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_plot = ['word_count', 'stopword_count', 'stopword_percentage', 'non_stopword_count', 'non_stopword_percentage','avg_word_length', 'avg_sent_length', 'paragraph_count','readability_score']\n",
    "fig, axes = plt.subplots(nrows=len(metrics_to_plot), ncols=2, figsize=(15, 6 * len(metrics_to_plot)))\n",
    "\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "  # Bar plot\n",
    "  ax_bar = axes[idx, 0]\n",
    "  sns.barplot(x=article_metrics_with_categories[\"broad_category\"], y=article_metrics_with_categories[metric], errorbar=(\"ci\", 95), ax=ax_bar)\n",
    "  ax_bar.set_xlabel(\"Category\")\n",
    "  ax_bar.set_ylabel(metric)\n",
    "  ax_bar.set_title(\"Mean and CI of {} per Category\".format(metric))\n",
    "  ax_bar.set_xticklabels(ax_bar.get_xticklabels(), rotation=90)\n",
    "\n",
    "  # Violin plot\n",
    "  ax_violin = axes[idx, 1]\n",
    "  sns.violinplot(x=article_metrics_with_categories[\"broad_category\"], y=article_metrics_with_categories[metric], ax=ax_violin)\n",
    "  ax_violin.set_xlabel(\"Category\")\n",
    "  ax_violin.set_ylabel(metric)\n",
    "  ax_violin.set_title(\"Distribution of {} per Category\".format(metric))\n",
    "  ax_violin.set_xticklabels(ax_violin.get_xticklabels(), rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Articles metrics per finished vs unfinished paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the article metrics per finished and unfinished parths (both for start and end articles)\n",
    "start_finished_article_metrics = finished_paths.merge(article_metrics_with_categories, how=\"left\", left_on=\"start\", right_on=\"article\")\n",
    "end_finished_article_metrics = finished_paths.merge(article_metrics_with_categories, how=\"left\", left_on=\"target\", right_on=\"article\")\n",
    "start_unfinished_article_metrics = unfinished_paths.merge(article_metrics_with_categories, how=\"left\", left_on=\"start\", right_on=\"article\")\n",
    "end_unfinished_article_metrics = unfinished_paths.merge(article_metrics_with_categories, how=\"left\", left_on=\"target\", right_on=\"article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_plot = [\"word_count\", \"stopword_count\", \"stopword_percentage\", \"non_stopword_count\", \"non_stopword_percentage\",\"avg_word_length\", \"avg_sent_length\", \"paragraph_count\", \"readability_score\"]\n",
    "dataframes = [start_finished_article_metrics, start_unfinished_article_metrics, end_finished_article_metrics, end_unfinished_article_metrics]\n",
    "dataframe_labels = [\"Start Finished\", \"Start Unfinished\", \"Target Finished\", \"Target Unfinished\"]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(metrics_to_plot), ncols=2, figsize=(15, 6 * len(metrics_to_plot)))\n",
    "\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "  data = [df[metric] for df in dataframes]\n",
    "  \n",
    "  # Bar plot\n",
    "  ax_bar = axes[idx, 0]\n",
    "  sns.barplot(data=data, errorbar=(\"ci\", 95), ax=ax_bar)\n",
    "  ax_bar.set_xlabel(\"Type of article\")\n",
    "  ax_bar.set_ylabel(metric)\n",
    "  ax_bar.set_title(\"Mean and CI of {} per Category\".format(metric))\n",
    "  ax_bar.set_xticklabels(dataframe_labels)\n",
    "\n",
    "  # Violin plot\n",
    "  ax_violin = axes[idx, 1]\n",
    "  sns.violinplot(data=data, ax=ax_violin)\n",
    "  ax_bar.set_xlabel(\"Type of article\")\n",
    "  ax_violin.set_ylabel(metric)\n",
    "  ax_violin.set_title(\"Distribution of {} per Category\".format(metric))\n",
    "  ax_violin.set_xticklabels(dataframe_labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start Articles (comparing finished vs unfinished):\")\n",
    "t_test_article_metrics(metrics_to_plot, start_finished_article_metrics, start_unfinished_article_metrics)\n",
    "\n",
    "print(\"\\nTarget Articles (comparing finished vs unfinished):\")\n",
    "t_test_article_metrics(metrics_to_plot, end_finished_article_metrics, end_unfinished_article_metrics)\n",
    "\n",
    "print(\"\\nFinished Articles (comparing start vs target):\")\n",
    "t_test_article_metrics(metrics_to_plot, start_finished_article_metrics, end_finished_article_metrics)\n",
    "\n",
    "print(\"\\nUnfinished Articles (comparing start vs target):\")\n",
    "t_test_article_metrics(metrics_to_plot, start_unfinished_article_metrics, end_unfinished_article_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze links to targets in finished vs unfinished articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished_paths[\"links_to_target\"] = finished_paths[\"path\"].apply(lambda x: len(edges.loc[edges[\"end\"] == x[-1]]))\n",
    "unfinished_paths[\"links_to_target\"] = unfinished_paths[\"target\"].apply(lambda x: len(edges.loc[edges[\"end\"] == x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing mean number of links to the targets in the finished and unfinished paths.\n",
    "print(f\"The targets that were reached had {finished_paths['links_to_target'].mean()} links on average pointing to them.\")\n",
    "print(f\"The targets that were not reached had {unfinished_paths['links_to_target'].mean()} links on average pointing to them.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conducting a t-test\n",
    "stats.ttest_ind(finished_paths[\"links_to_target\"], unfinished_paths[\"links_to_target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a boxplot of the trends\n",
    "\n",
    "finished_links =  pd.DataFrame()\n",
    "finished_links[\"links_to_target\"] = finished_paths[\"links_to_target\"]\n",
    "finished_links[\"path_type\"] = \"Finished paths\"\n",
    "\n",
    "unfinished_links =  pd.DataFrame()\n",
    "unfinished_links[\"links_to_target\"] = unfinished_paths[\"links_to_target\"]\n",
    "unfinished_links[\"path_type\"] = \"Unfinished paths\"\n",
    "\n",
    "df_links = pd.concat([finished_links,unfinished_links])\n",
    "\n",
    "ax = sns.boxplot(x=\"path_type\", y=\"links_to_target\", data=df_links)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylim([-5,155])\n",
    "plt.ylabel(\"Number of links to target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value of a t-test between the number of links pointing to the targets of finished and unfinished paths is 0.0. This means we reject the null hypothesis that the number of links pointing to the targets are statistically the same at the 5% level of significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse possible shortest path distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the shortest possible paths for the finished games\n",
    "\n",
    "finished_paths[\"shortest_path_length\"] = finished_paths[\"path\"].apply(\n",
    "    lambda x: shortest_paths[articles.loc[articles['article'] == x[0]].index[0]][articles.loc[articles['article'] == x[-1]].index[0]]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE IMPORTANT: THERE ARE TYPOS\n",
    "\n",
    "\n",
    "Eg. At index 141 in unfinished paths, the target is written as \"Long_peper\", when it should be \"Long_pepper\"\n",
    "\n",
    "Overall, 28 times an issue arises in unfinished paths. Doesn't seem to be an issue in finished paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the shortest possible paths for the unfinished games\n",
    "\n",
    "shortest_unfinished = []\n",
    "not_found = 0\n",
    "for i in range(len(unfinished_paths)):\n",
    "    source = articles.loc[articles['article'] == unfinished_paths.iloc[i][\"path\"][0]]\n",
    "    target = articles.loc[articles['article'] == unfinished_paths.iloc[i][\"target\"]]\n",
    "    if len(source) != 0 and len(target) != 0:\n",
    "        index_source = source.index[0]\n",
    "        index_target = target.index[0]\n",
    "        shortest_unfinished.append(int(shortest_paths[index_source][index_target]))\n",
    "    else:\n",
    "        shortest_unfinished.append(None)\n",
    "        not_found+=1\n",
    "\n",
    "unfinished_paths[\"shortest_path_length\"] = shortest_unfinished\n",
    "print(f\"{not_found} shortest paths not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing to see if there are issues in the finished paths too\n",
    "\n",
    "shortest_finished = []\n",
    "not_found2 = 0\n",
    "for i in range(len(finished_paths)):\n",
    "    source = articles.loc[articles['article'] == finished_paths.iloc[i][\"path\"][0]]\n",
    "    target = articles.loc[articles['article'] == finished_paths.iloc[i][\"path\"][-1]]\n",
    "    if len(source) != 0 and len(target) != 0:\n",
    "        index_source = source.index[0]\n",
    "        index_target = target.index[0]\n",
    "        shortest_finished.append(int(shortest_paths[index_source][index_target]))\n",
    "    else:\n",
    "        shortest_finished.append(None)\n",
    "        not_found2+=1\n",
    "\n",
    "print(f\"{not_found2} shortest paths not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting number of \"impossible\" paths\n",
    "\n",
    "print(f\"There are {len(finished_paths[finished_paths['shortest_path_length'] == 255])} impossible finished paths.\")\n",
    "print(f\"There are {len(unfinished_paths[unfinished_paths['shortest_path_length'] == 255])} impossible unfinished paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing mean shortest possible paths in the finished and unfinished paths.\n",
    "print(f\"The shortest possible paths were {finished_paths['shortest_path_length'].mean()} long on average in the finished paths.\")\n",
    "print(f\"The shortest possible paths were {unfinished_paths['shortest_path_length'].mean()} long on average in the unfinished paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing a t test on the shortest path lengths\n",
    "stats.ttest_ind(finished_paths['shortest_path_length'], unfinished_paths['shortest_path_length'], nan_policy=\"omit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a boxplot of the trends\n",
    "\n",
    "finished_shortest =  pd.DataFrame()\n",
    "finished_shortest[\"shortest_path_length\"] = finished_paths[finished_paths['shortest_path_length'] != 255][\"shortest_path_length\"]\n",
    "finished_shortest[\"path_type\"] = \"Finished paths\"\n",
    "\n",
    "unfinished_shortest =  pd.DataFrame()\n",
    "unfinished_shortest[\"shortest_path_length\"] = unfinished_paths[unfinished_paths['shortest_path_length'] != 255][\"shortest_path_length\"]\n",
    "unfinished_shortest[\"path_type\"] = \"Unfinished paths\"\n",
    "\n",
    "df_shortest = pd.concat([finished_shortest,unfinished_shortest])\n",
    "\n",
    "ax = sns.boxplot(x=\"path_type\", y=\"shortest_path_length\", data=df_shortest)\n",
    "plt.xlabel(\" \")\n",
    "#plt.ylim([-5,155])\n",
    "plt.ylabel(\"Shortest path possible from source to target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t test shows that indeed this is a significant difference. Unfinished paths are thus inherently more difficult to get to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an interesting situation. The past two analyses show that the targets are more difficult to get to in the unfinished paths, due to the fewer links that point at them and the larger value of the possible shortest path to them.\n",
    "\n",
    "A challenge for us may be to try to isolate whether the difference between whether a path is finished or not can be fully explained by more objective factors like this, or if there is a human component that we can isolate as well. Eg, are some categories actually more difficult to get to, or do the differences in the target category distributions in the finished and unfinished paths arise because some categories may be more likely to have longer possible shortest paths to them or have fewer links pointing at them?\n",
    "\n",
    "We should explore these ideas\n",
    "\n",
    "TODO: Start working on the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Networkx graph objects \n",
    "degreehistograms, etc. etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything together\n",
    "put all article clicks (before and after giving up, also include all succesfully finished paths) in a wide form df to run statistical anaylsis\n",
    "- merge with article metrics\n",
    "- merge with article categories\n",
    "- merge with game information\n",
    "- merge with player information\n",
    "- merge with backclick information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_information = article_metrics.copy()\n",
    "article_information[\"article_name\"] = article_information[\"file_name\"].apply(lambda name: name.split(\".\")[0])\n",
    "\n",
    "# merge in categories\n",
    "article_information = pd.merge(article_information, categories[[\"article\", \"broad_category\"]], how=\"left\", left_on=\"article_name\", right_on=\"article\")\n",
    "\n",
    "keep = ['article_name',\n",
    "        'word_count',\n",
    "        'non_stopword_count',\n",
    "        'stopword_count',\n",
    "        'avg_word_length',\n",
    "        'avg_sent_length',\n",
    "        'paragraph_count',\n",
    "        'readability_score',\n",
    "        'broad_category']\n",
    "\n",
    "article_information = article_information[keep]\n",
    "article_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exploration per actual link "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create all links (with duplicates) and add a game ID (e.g., index of finsihed and unfinished path)\n",
    "\n",
    "# add IDs\n",
    "finished_paths[\"game_id\"] = \"F\" + pd.Series(finished_paths.index).astype(str)\n",
    "unfinished_paths[\"game_id\"] = \"U\" + pd.Series(unfinished_paths.index).astype(str)\n",
    "\n",
    "def get_all_clicks(df):\n",
    "    out = []\n",
    "    for index, row in df.iterrows():\n",
    "        links = row['path'].split(';')\n",
    "        \n",
    "        edges = list(pairwise(links))\n",
    "        game_id = row[\"game_id\"]\n",
    "        to_add = []\n",
    "        clicks = 1\n",
    "        for edge in edges:\n",
    "            source, target = edge\n",
    "            clicks += 1\n",
    "            out.append([source, target, clicks, game_id])\n",
    "\n",
    "\n",
    "    out = pd.DataFrame(out, columns=[\"source\", \"target\", \"num_step\", \"game_id\"])\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add \n",
    "finished_clicks = get_all_clicks(finished_paths)\n",
    "finished_clicks[\"give_up\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfinished_paths_sample = unfinished_paths[unfinished_paths.path_length > 3]\n",
    "unfinished_clicks = get_all_clicks(unfinished_paths_sample)\n",
    "unfinished_clicks[\"give_up\"] = 0\n",
    "unfinished_clicks.loc[unfinished_clicks.groupby('game_id').tail(1).index, 'give_up'] = 1\n",
    "unfinished_clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clicks = pd.concat((finished_clicks.sample(10_000), unfinished_clicks), axis=0)\n",
    "all_clicks = all_clicks.merge(article_information, how=\"left\", left_on=\"source\", right_on=\"article_name\")\n",
    "all_clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_clicks.dropna()\n",
    "print(data.give_up.sum())\n",
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "mod = smf.logit(formula='give_up ~ num_step + word_count + non_stopword_count + stopword_count + avg_word_length + avg_sent_length + paragraph_count + readability_score + C(broad_category)', data=data)\n",
    "res = mod.fit(maxiter=100)\n",
    "print(res.summary())\n",
    "\n",
    "# not that interesting, the fiut is very very bad, it doesnt converge\n",
    "# also, only statistically relevant thing is average sentence lenght."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration per Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do same analysis on game level - can we predict whether they will give up before the game even started?\n",
    "\n",
    "unfinished_paths[\"start\"] = unfinished_paths.path.apply(lambda el: el.split(\";\")[0])\n",
    "unfinished_paths[\"give_up\"] = 1\n",
    "\n",
    "# add start plus end category\n",
    "finished_paths[\"start\"] = finished_paths.path.apply(lambda el: el.split(\";\")[0])\n",
    "finished_paths[\"target\"] = finished_paths.path.apply(lambda el: el.split(\";\")[-1])\n",
    "finished_paths[\"give_up\"] = 0\n",
    "\n",
    "\n",
    "keep = [\"start\", \"target\", \"give_up\", \"shortest_path\", \"links_to_target\"]\n",
    "data = pd.concat((finished_paths[keep], unfinished_paths[keep]), axis=0)\n",
    "data = data.merge(article_information[[\"article_name\", \"broad_category\"]], how=\"left\", left_on=\"start\", right_on=\"article_name\")\n",
    "data = data.merge(article_information[[\"article_name\", \"broad_category\"]], how=\"left\", left_on=\"target\", right_on=\"article_name\")\n",
    "data = data.drop([\"article_name_x\", \"article_name_y\"], axis=1)\n",
    "data[\"not_same_cat\"] = data[\"broad_category_x\"] != data[\"broad_category_y\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "mod = smf.logit(formula='give_up ~ C(broad_category_y) + C(broad_category_x) + not_same_cat + shortest_path + links_to_target', data=data)\n",
    "res = mod.fit(maxiter=100)\n",
    "print(res.summary())\n",
    "\n",
    "### Interesting takeawys: \n",
    "# some categories are statistically significnat (.e.g, countries, geography) and lower the probability\n",
    "# some categories increase the proabaility\n",
    "# having to switch categories from source to target increases the probability\n",
    "# shortest path: the longer the shortest path, the higher the probability of giving up.\n",
    "\n",
    "### We can easily further expand this analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
