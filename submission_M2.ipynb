{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA CAPI Notebook for Project Milestone 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "1. Loading and Preparing the Data\n",
    "2. Data Extraction\n",
    "3. Data Analysis\n",
    "4. Putting everything together\n",
    "5. Initial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats \n",
    "\n",
    "# Helper functions from utils folder\n",
    "from utils.analysis import t_test_article_metrics, visualize_article_connections_per_category\n",
    "from utils.preprocessing import get_all_links, merge_articles_categories, create_category_dictionaries\n",
    "\n",
    "# Formatting libraries\n",
    "import urllib\n",
    "import datetime as datetime\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Imports to perform article analysis\n",
    "import textstat\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt') # Punkt tokenizer\n",
    "nltk.download('stopwords') # Commong stopwords\n",
    "\n",
    "# Load config and extract variables\n",
    "import config\n",
    "DATA_PATH = config.PATH_TO_DATA\n",
    "PATH_GRAPGH_FOLDER = \"wikispeedia_paths-and-graph\"\n",
    "ARTICLE_FOLDER = \"plaintext_articles\"\n",
    "GENERATED_METRICS = \"generated_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Loading and Preparing the Data\n",
    "Note that you can load the data from below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in all data (except wikipedia articles)\n",
    "finished_paths = pd.read_csv(os.path.join(DATA_PATH, PATH_GRAPGH_FOLDER, \"paths_finished.tsv\"), sep='\\t', skiprows=15, \n",
    "                             names=[\"hashedIpAddress\", \"timestamp\", \"durationInSec\", \"path\", \"rating\"])\n",
    "unfinished_paths = pd.read_csv(os.path.join(DATA_PATH, PATH_GRAPGH_FOLDER, \"paths_unfinished.tsv\"), sep='\\t', skiprows=16, \n",
    "                               names=[\"hashedIpAddress\", \"timestamp\", \"durationInSec\", \"path\", \"target\", \"type\"])\n",
    "edges = pd.read_csv(os.path.join(DATA_PATH, PATH_GRAPGH_FOLDER, \"links.tsv\"), sep='\\t', skiprows=15, names=[\"start\", \"end\"], encoding=\"utf-8\")\n",
    "articles = pd.read_csv(os.path.join(DATA_PATH, PATH_GRAPGH_FOLDER, \"articles.tsv\"), sep='\\t', skiprows=12, names=[\"article\"], encoding=\"utf-8\")\n",
    "categories = pd.read_csv(os.path.join(DATA_PATH, PATH_GRAPGH_FOLDER, \"categories.tsv\"), sep='\\t', skiprows=13, \n",
    "                         names=[\"article\", \"category\"], encoding=\"utf-8\")\n",
    "shortest_paths = np.genfromtxt(os.path.join(DATA_PATH, PATH_GRAPGH_FOLDER, \"shortest-path-distance-matrix.txt\"), delimiter=1, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up edge list\n",
    "display(edges.head())\n",
    "edges[\"start\"] = edges.start.apply(urllib.parse.unquote)\n",
    "edges[\"end\"] = edges.end.apply(urllib.parse.unquote)\n",
    "display(edges.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format datetime as datetime object\n",
    "display(articles.head())\n",
    "finished_paths[\"datetime\"] = finished_paths.timestamp.apply(datetime.datetime.fromtimestamp)\n",
    "unfinished_paths[\"datetime\"] = unfinished_paths.timestamp.apply(datetime.datetime.fromtimestamp)\n",
    "display(unfinished_paths.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up url encoding for articles\n",
    "display(articles.head())\n",
    "articles[\"article\"] = articles.article.apply(urllib.parse.unquote)\n",
    "display(articles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up url encoding for categories\n",
    "display(categories.head())\n",
    "categories[\"article\"] = categories.article.apply(urllib.parse.unquote)\n",
    "display(categories.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify broad categories of articles\n",
    "display(categories.head())\n",
    "categories[\"broad_category\"] = categories[\"category\"].apply(lambda x: x.split(\".\")[1])\n",
    "display(categories.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge articles and categories\n",
    "articles_categories = pd.merge(articles, categories, how=\"left\", on=\"article\")\n",
    "display(articles_categories.head())\n",
    "# 6 articles without category!\n",
    "print(\"Merge introduced {} NAs in category columns:\".format(articles_categories.category.isna().sum()))\n",
    "articles_categories[articles_categories.category.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert paths to a readable format (lists)\n",
    "finished_paths[\"path\"] = finished_paths[\"path\"].apply(lambda x: x.split(\";\"))\n",
    "finished_paths[\"path\"] = finished_paths[\"path\"].apply(lambda x: [urllib.parse.unquote(y) for y in x])\n",
    "\n",
    "unfinished_paths[\"path\"] = unfinished_paths[\"path\"].apply(lambda x: x.split(\";\"))\n",
    "unfinished_paths[\"path\"] = unfinished_paths[\"path\"].apply(lambda x: [urllib.parse.unquote(y) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add start and target articles of path\n",
    "finished_paths[\"start\"] = [path[0] for path in finished_paths[\"path\"]]\n",
    "finished_paths[\"target\"] = [path[-1] for path in finished_paths[\"path\"]]\n",
    "\n",
    "unfinished_paths[\"start\"] = [path[0] for path in unfinished_paths[\"path\"]]\n",
    "unfinished_paths[\"target\"] = unfinished_paths[\"target\"].apply(urllib.parse.unquote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all finished links\n",
    "finished_links = get_all_links(finished_paths)\n",
    "finished_links.sort_values(by=\"weight\", ascending=False) # TODO: what is up with these <<< signs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unfinished links\n",
    "unfinished_links = get_all_links(unfinished_paths)\n",
    "unfinished_links.sort_values(by=\"weight\", ascending=False) # TODO: what is up with these <<< signs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create newtorkx graph from finished paths\n",
    "finished_graph = nx.from_pandas_edgelist(finished_links,source=\"source\", target=\"target\", edge_attr=\"weight\")\n",
    "hist = nx.degree_histogram(finished_graph)\n",
    "plt.bar(range(len(hist)), hist)\n",
    "pd.Series(hist).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create newtorkx graph from unfinished paths\n",
    "unfinished_graph = nx.from_pandas_edgelist(unfinished_links,source=\"source\", target=\"target\", edge_attr=\"weight\")\n",
    "hist = nx.degree_histogram(unfinished_graph)\n",
    "plt.bar(range(len(hist)), hist)\n",
    "pd.Series(hist).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting number of \"impossible\" paths\n",
    "\n",
    "print(f\"There are {len(finished_paths[finished_paths['shortest_path_length'] == 255])} impossible finished paths.\")\n",
    "print(f\"There are {len(unfinished_paths[unfinished_paths['shortest_path_length'] == 255])} impossible unfinished paths.\")\n",
    "\n",
    "# These will be ignored in the following analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting article metrics\n",
    "\n",
    "* Total word count: To understand the length of the article.\n",
    "* Non stopword frequency: To identify words that contribute to the content's meaning.\n",
    "* Stopword frequency: To identify common words that may not contribute to the content's meaning.\n",
    "* Average word length: To assess the complexity of the language used.\n",
    "* Average sentence length: Longer or more complex sentences (based on characters) may contribute to frustration.\n",
    "* Number of paragraphs: To see if the article's structure plays a role in people giving up.\n",
    "* Keyword frequency: To identify the most common keywords to understand the article's focus.\n",
    "* Readability: Ease of reading the article (metric: Flesch Reading Ease Score) Link: https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proprocess_article(article_text):\n",
    "    preprocessed_text = article_text\n",
    "    preprocessed_text = preprocessed_text.lower()\n",
    "    preprocessed_text = preprocessed_text.replace(\"\\n   \", \" \") # As the articles are not continuous sentences\n",
    "    return preprocessed_text\n",
    "\n",
    "def calculate_article_metrics(article_text):\n",
    "    preprocessed_text = proprocess_article(article_text)\n",
    "\n",
    "    words = word_tokenize(preprocessed_text)\n",
    "    sentences = sent_tokenize(preprocessed_text)\n",
    "\n",
    "    # Calculate total word count\n",
    "    total_word_count = len(words)\n",
    "\n",
    "    # Calculate stopword frequency\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    stopwords_count = 0\n",
    "    unique_words = []\n",
    "    for word in words:\n",
    "        if word.isalpha() and word.lower() in stop_words:\n",
    "            stopwords_count +=1\n",
    "        if word.isalpha() and word.lower() not in stop_words:\n",
    "            unique_words.append(word.lower())\n",
    "\n",
    "    # Calculate average word length\n",
    "    average_word_length = sum(len(word) for word in words) / total_word_count\n",
    "\n",
    "    # Calculate average sentence length\n",
    "    average_sentence_length = sum(len(sentence) for sentence in sentences) / len(sentences)\n",
    "\n",
    "    # Calculate number of paragraphs (assume every new line \\n is paragraph)\n",
    "    paragraphs_count = preprocessed_text.count('\\n') + 1 # Count last paragraph\n",
    "\n",
    "    # Calculate keyword frequency\n",
    "    word_freq = nltk.FreqDist(unique_words)\n",
    "    most_common_words = word_freq.most_common(10)  # Parameter to adjust\n",
    "\n",
    "    # Calculate readability (Flesch Reading Ease Score) - 100: Easy to read, 0: Very confusing\n",
    "    readability = textstat.flesch_reading_ease(preprocessed_text)\n",
    "\n",
    "    return {\n",
    "        \"word_count\": total_word_count,\n",
    "        \"non_stopword_count\": total_word_count - stopwords_count,\n",
    "        \"stopword_count\": stopwords_count,\n",
    "        \"avg_word_length\": average_word_length,\n",
    "        \"avg_sent_length\": average_sentence_length,\n",
    "        \"paragraph_count\": paragraphs_count,\n",
    "        \"common_words\": most_common_words,\n",
    "        \"readability_score\": readability,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the article data\n",
    "To reduce runtime, we compute the article metrics once and then read the generated csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "folder_path = os.path.join(DATA_PATH, ARTICLE_FOLDER)\n",
    "if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "\n",
    "  article_metrics = pd.DataFrame(columns=[\"article\", \"word_count\", \"non_stopword_count\", \"stopword_count\", \"avg_word_length\", \"avg_sent_length\", \"paragraph_count\", \"common_words\", \"readability_score\"])\n",
    "\n",
    "  for file_name in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    if os.path.isfile(file_path):\n",
    "      root, extension = os.path.splitext(file_name)\n",
    "      readable_file_name = urllib.parse.unquote(root)\n",
    "      \n",
    "      with open(file_path, \"r\", encoding=\"utf-8\") as article:\n",
    "        metrics = calculate_article_metrics(article.read())\n",
    "\n",
    "        metrics[\"article\"] = readable_file_name\n",
    "        article_metrics.loc[len(article_metrics)] = metrics\n",
    "else:\n",
    "  raise FileNotFoundError(\"The specified folder path does not exist or is not a directory.\")\n",
    "\n",
    "article_metrics.to_csv(os.path.join(GENERATED_METRICS, \"article_metrics.csv\"), index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_metrics = pd.read_csv(os.path.join(GENERATED_METRICS, \"article_metrics.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_metrics[\"stopword_percentage\"] = article_metrics[\"stopword_count\"] / article_metrics[\"word_count\"]\n",
    "article_metrics[\"non_stopword_percentage\"] = article_metrics[\"non_stopword_count\"] / article_metrics[\"word_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(article_metrics.info())\n",
    "display(article_metrics.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring Path Lengths across Finished and Unfinished Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of path lengths disaggregated across finished and unfinished\n",
    "unfinished_paths[\"path_length\"] = unfinished_paths.path.apply(lambda el: len(el))\n",
    "finished_paths[\"path_length\"] = finished_paths.path.apply(lambda el: len(el))\n",
    "\n",
    "print(\"Finished Paths: Length\")\n",
    "display(finished_paths[\"path_length\"].describe())\n",
    "display(finished_paths.path_length.value_counts())\n",
    "\n",
    "print(\"Unfinished Paths: Length\")\n",
    "display(unfinished_paths[\"path_length\"].describe())\n",
    "unfinished_paths.path_length.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot of path lengths\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 4), sharey=True)\n",
    "\n",
    "sns.histplot(data=finished_paths, x=\"path_length\", ax=axes[0])\n",
    "axes[0].set_title(\"Finished Paths\")\n",
    "sns.histplot(data=unfinished_paths, x=\"path_length\", ax=axes[1], hue=\"type\")\n",
    "axes[1].set_title(\"Uninished Paths\")\n",
    "\n",
    "# --> highly skewed and many unlikely outcomes (e.g. unfinished paths path length = 1, did they really give up? or not play at all?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot of path lengths\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(14, 4), sharey=True)\n",
    "threshold = 30\n",
    "\n",
    "\n",
    "sns.histplot(x=finished_paths.path_length[finished_paths.path_length < threshold], ax=axes[0], discrete=True)\n",
    "axes[0].set_title(\"Finished Paths\")\n",
    "\n",
    "unfinished_clean = unfinished_paths[(unfinished_paths.path_length < threshold) & (unfinished_paths.type == \"restart\")]\n",
    "sns.histplot(data=unfinished_clean, x=\"path_length\", ax=axes[1], discrete=True,)\n",
    "axes[1].set_title(\"Uninished Paths - Restart\")\n",
    "\n",
    "unfinished_clean = unfinished_paths[(unfinished_paths.path_length < threshold) & (unfinished_paths.type == \"timeout\")]\n",
    "sns.histplot(data=unfinished_clean, x=\"path_length\", ax=axes[2], discrete=True,)\n",
    "axes[2].set_title(\"Uninished Paths - Timeout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 -Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring Categories in the Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing which categories are most represented in articles\n",
    "count_articles = categories.groupby(\"broad_category\").size()\n",
    "\n",
    "print(\"Below shows how many articles each of the broad categories are represented by\")\n",
    "display(count_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries for easy discovery of what categories an article belongs to\n",
    "article_to_category, article_to_broad_category = create_category_dictionaries(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times each category has occured as a target in the finished and unfinished paths.\n",
    "# Note that some articles are represented by multiple categories, which are thus counted extra.\n",
    "\n",
    "all_target_broad_categories_f = [\n",
    "  article_to_broad_category[target] for target in finished_paths[\"target\"] if target in article_to_broad_category\n",
    "]\n",
    "all_target_broad_categories_f = [item for sublist in all_target_broad_categories_f for item in sublist]\n",
    "count_cats_finished_target = Counter(all_target_broad_categories_f)\n",
    "keys_finished = list(count_cats_finished_target.keys())\n",
    "keys_finished.sort()\n",
    "sorted_cats_f = {i: count_cats_finished_target[i] for i in keys_finished}\n",
    "\n",
    "all_target_broad_categories_u = [\n",
    "  article_to_broad_category[target] for target in unfinished_paths[\"target\"] if target in article_to_broad_category\n",
    "]\n",
    "all_target_broad_categories_u = [item for sublist in all_target_broad_categories_u for item in sublist]\n",
    "count_cats_unfinished_target = Counter(all_target_broad_categories_u)\n",
    "keys_unfinished = list(count_cats_unfinished_target.keys())\n",
    "keys_unfinished.sort()\n",
    "sorted_cats_u = {i: count_cats_unfinished_target[i] for i in keys_unfinished}\n",
    "\n",
    "# Plotting the results\n",
    "ax = plt.barh(list(sorted_cats_f.keys()), sorted_cats_f.values(), label=\"Finished paths\")\n",
    "ax2 = plt.barh(list(sorted_cats_u.keys()), sorted_cats_u.values(), label=\"Unfinished paths\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.title(\"Occurences of categories as targets\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring subject strength in connected articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing FINISHED PATHS article connections per category\n",
    "edge_category = merge_articles_categories(edges, [\"start\", \"end\"], articles_categories)\n",
    "visualize_article_connections_per_category(edge_category, \"Article Connections Based on Category (Normalized and Scaled Edges)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing FINISHED PATHS article connections per category\n",
    "finished_paths_categories = merge_articles_categories(finished_paths, [\"start\", \"target\"], articles_categories)\n",
    "visualize_article_connections_per_category(finished_paths_categories, \"Start & Target Article Connections in Finished Path Based on Category (Normalized and Scaled Edges)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing UNFINISHED PATHS article connections per category\n",
    "unfinished_paths_categories = merge_articles_categories(unfinished_paths, [\"start\", \"target\"], articles_categories)\n",
    "visualize_article_connections_per_category(unfinished_paths_categories, \"Start & Target Article Connections in Unfinished Path Based on Category (Normalized and Scaled Edges)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing article metrics by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge articles with their corresponding categories\n",
    "article_metrics_with_categories = article_metrics.merge(categories, how=\"left\", on=[\"article\"])\n",
    "display(article_metrics_with_categories.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_plot = ['word_count', 'stopword_count', 'stopword_percentage', 'non_stopword_count', 'non_stopword_percentage','avg_word_length', 'avg_sent_length', 'paragraph_count','readability_score']\n",
    "fig, axes = plt.subplots(nrows=len(metrics_to_plot), ncols=2, figsize=(15, 6 * len(metrics_to_plot)))\n",
    "\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "  # Bar plot\n",
    "  ax_bar = axes[idx, 0]\n",
    "  sns.barplot(x=article_metrics_with_categories[\"broad_category\"], y=article_metrics_with_categories[metric], errorbar=(\"ci\", 95), ax=ax_bar)\n",
    "  ax_bar.set_xlabel(\"Category\")\n",
    "  ax_bar.set_ylabel(metric)\n",
    "  ax_bar.set_title(\"Mean and CI of {} per Category\".format(metric))\n",
    "  ax_bar.set_xticklabels(ax_bar.get_xticklabels(), rotation=90)\n",
    "\n",
    "  # Violin plot\n",
    "  ax_violin = axes[idx, 1]\n",
    "  sns.violinplot(x=article_metrics_with_categories[\"broad_category\"], y=article_metrics_with_categories[metric], ax=ax_violin)\n",
    "  ax_violin.set_xlabel(\"Category\")\n",
    "  ax_violin.set_ylabel(metric)\n",
    "  ax_violin.set_title(\"Distribution of {} per Category\".format(metric))\n",
    "  ax_violin.set_xticklabels(ax_violin.get_xticklabels(), rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing article metrics in finished vs unfinished paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the article metrics per finished and unfinished parths (both for start and end articles)\n",
    "start_finished_article_metrics = finished_paths.merge(article_metrics_with_categories, how=\"left\", left_on=\"start\", right_on=\"article\")\n",
    "end_finished_article_metrics = finished_paths.merge(article_metrics_with_categories, how=\"left\", left_on=\"target\", right_on=\"article\")\n",
    "start_unfinished_article_metrics = unfinished_paths.merge(article_metrics_with_categories, how=\"left\", left_on=\"start\", right_on=\"article\")\n",
    "end_unfinished_article_metrics = unfinished_paths.merge(article_metrics_with_categories, how=\"left\", left_on=\"target\", right_on=\"article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_plot = [\"word_count\", \"stopword_count\", \"stopword_percentage\", \"non_stopword_count\", \"non_stopword_percentage\",\"avg_word_length\", \"avg_sent_length\", \"paragraph_count\", \"readability_score\"]\n",
    "dataframes = [start_finished_article_metrics, start_unfinished_article_metrics, end_finished_article_metrics, end_unfinished_article_metrics]\n",
    "dataframe_labels = [\"Start Finished\", \"Start Unfinished\", \"Target Finished\", \"Target Unfinished\"]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(metrics_to_plot), ncols=2, figsize=(15, 6 * len(metrics_to_plot)))\n",
    "\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "  data = [df[metric] for df in dataframes]\n",
    "  \n",
    "  # Bar plot\n",
    "  ax_bar = axes[idx, 0]\n",
    "  sns.barplot(data=data, errorbar=(\"ci\", 95), ax=ax_bar)\n",
    "  ax_bar.set_xlabel(\"Type of article\")\n",
    "  ax_bar.set_ylabel(metric)\n",
    "  ax_bar.set_title(\"Mean and CI of {} per Category\".format(metric))\n",
    "  ax_bar.set_xticklabels(dataframe_labels)\n",
    "\n",
    "  # Violin plot\n",
    "  ax_violin = axes[idx, 1]\n",
    "  sns.violinplot(data=data, ax=ax_violin)\n",
    "  ax_bar.set_xlabel(\"Type of article\")\n",
    "  ax_violin.set_ylabel(metric)\n",
    "  ax_violin.set_title(\"Distribution of {} per Category\".format(metric))\n",
    "  ax_violin.set_xticklabels(dataframe_labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start Articles (comparing finished vs unfinished):\")\n",
    "t_test_article_metrics(metrics_to_plot, start_finished_article_metrics, start_unfinished_article_metrics)\n",
    "\n",
    "print(\"\\nTarget Articles (comparing finished vs unfinished):\")\n",
    "t_test_article_metrics(metrics_to_plot, end_finished_article_metrics, end_unfinished_article_metrics)\n",
    "\n",
    "print(\"\\nFinished Articles (comparing start vs target):\")\n",
    "t_test_article_metrics(metrics_to_plot, start_finished_article_metrics, end_finished_article_metrics)\n",
    "\n",
    "print(\"\\nUnfinished Articles (comparing start vs target):\")\n",
    "t_test_article_metrics(metrics_to_plot, start_unfinished_article_metrics, end_unfinished_article_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing the number of links to target in finished vs unfinished paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting how many links point to targets in finished and unfinished paths\n",
    "finished_paths[\"links_to_target\"] = finished_paths[\"path\"].apply(lambda x: len(edges.loc[edges[\"end\"] == x[-1]]))\n",
    "unfinished_paths[\"links_to_target\"] = unfinished_paths[\"target\"].apply(lambda x: len(edges.loc[edges[\"end\"] == x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing mean number of links to the targets in the finished and unfinished paths.\n",
    "print(\"The targets that were reached had {:.3f} links on average pointing to them.\".format(finished_paths['links_to_target'].mean()))\n",
    "print(\"The targets that were not reached had {:.3f} links on average pointing to them.\".format(unfinished_paths['links_to_target'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conducting a t-test\n",
    "t_test_article_metrics([\"links_to_target\"], finished_paths, unfinished_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value of a t-test between the number of links pointing to the targets of finished and unfinished paths is 0.0. This means we reject the null hypothesis that the number of links pointing to the targets are statistically the same at the 5% level of significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a boxplot of the trends\n",
    "\n",
    "finished_links =  pd.DataFrame()\n",
    "finished_links[\"links_to_target\"] = finished_paths[\"links_to_target\"]\n",
    "finished_links[\"path_type\"] = \"Finished paths\"\n",
    "\n",
    "unfinished_links =  pd.DataFrame()\n",
    "unfinished_links[\"links_to_target\"] = unfinished_paths[\"links_to_target\"]\n",
    "unfinished_links[\"path_type\"] = \"Unfinished paths\"\n",
    "\n",
    "df_links = pd.concat([finished_links,unfinished_links])\n",
    "\n",
    "ax = sns.boxplot(x=\"path_type\", y=\"links_to_target\", data=df_links)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylim([-5,155])\n",
    "plt.ylabel(\"Number of links to target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing possible shortest path distances in finished vs unfinished paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the shortest possible paths for the finished games\n",
    "\n",
    "finished_paths[\"shortest_path_length\"] = finished_paths[\"path\"].apply(\n",
    "    lambda x: shortest_paths[articles.loc[articles['article'] == x[0]].index[0]][articles.loc[articles['article'] == x[-1]].index[0]]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important note: There are typos in the targets.\n",
    "\n",
    "Eg. At index 141 in unfinished paths, the target is written as \"Long_peper\", when it should be \"Long_pepper\".\n",
    "\n",
    "Overall, an issue arises in unfinished paths 28 times, but this doesn't seem to be an issue in finished paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the shortest possible paths for the unfinished games\n",
    "\n",
    "shortest_unfinished = []\n",
    "not_found = 0\n",
    "for i in range(len(unfinished_paths)):\n",
    "    source = articles.loc[articles['article'] == unfinished_paths.iloc[i][\"path\"][0]]\n",
    "    target = articles.loc[articles['article'] == unfinished_paths.iloc[i][\"target\"]]\n",
    "    if len(source) != 0 and len(target) != 0:\n",
    "        index_source = source.index[0]\n",
    "        index_target = target.index[0]\n",
    "        shortest_unfinished.append(int(shortest_paths[index_source][index_target]))\n",
    "    else:\n",
    "        shortest_unfinished.append(None)\n",
    "        not_found+=1\n",
    "\n",
    "unfinished_paths[\"shortest_path_length\"] = shortest_unfinished\n",
    "print(f\"{not_found} shortest paths not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing to see if there are issues in the finished paths too\n",
    "\n",
    "shortest_finished = []\n",
    "not_found2 = 0\n",
    "for i in range(len(finished_paths)):\n",
    "    source = articles.loc[articles['article'] == finished_paths.iloc[i][\"path\"][0]]\n",
    "    target = articles.loc[articles['article'] == finished_paths.iloc[i][\"path\"][-1]]\n",
    "    if len(source) != 0 and len(target) != 0:\n",
    "        index_source = source.index[0]\n",
    "        index_target = target.index[0]\n",
    "        shortest_finished.append(int(shortest_paths[index_source][index_target]))\n",
    "    else:\n",
    "        shortest_finished.append(None)\n",
    "        not_found2+=1\n",
    "\n",
    "print(f\"{not_found2} shortest paths not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing mean shortest possible paths in the finished and unfinished paths.\n",
    "\n",
    "print(\"The shortest possible paths were {:.3f} long on average in the finished paths.\".format(\n",
    "    finished_paths[finished_paths['shortest_path_length'] != 255]['shortest_path_length'].mean()\n",
    "    ))\n",
    "print(\"The shortest possible paths were {:.3f} long on average in the unfinished paths.\".format(\n",
    "    unfinished_paths[unfinished_paths['shortest_path_length'] != 255]['shortest_path_length'].mean()\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing a t test on the shortest path lengths\n",
    "t_test_article_metrics([\"shortest_path_length\"], finished_paths, unfinished_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value of a t-test between the shortest possible path lengths of finished and unfinished games is 0.0. This means we reject the null hypothesis that the shortest possible game paths are statistically the same across the two groups at the 5% level of significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a boxplot of the trends\n",
    "\n",
    "finished_shortest =  pd.DataFrame()\n",
    "finished_shortest[\"shortest_path_length\"] = finished_paths[finished_paths['shortest_path_length'] != 255][\"shortest_path_length\"]\n",
    "finished_shortest[\"path_type\"] = \"Finished paths\"\n",
    "\n",
    "unfinished_shortest =  pd.DataFrame()\n",
    "unfinished_shortest[\"shortest_path_length\"] = unfinished_paths[unfinished_paths['shortest_path_length'] != 255][\"shortest_path_length\"]\n",
    "unfinished_shortest[\"path_type\"] = \"Unfinished paths\"\n",
    "\n",
    "df_shortest = pd.concat([finished_shortest,unfinished_shortest])\n",
    "\n",
    "ax = sns.boxplot(x=\"path_type\", y=\"shortest_path_length\", data=df_shortest)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\"Shortest path possible from source to target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an interesting situation. The past two analyses show that the targets are more difficult to get to in the unfinished paths, due to the fewer links that point at them and the larger value of the possible shortest path to them.\n",
    "\n",
    "A challenge for us may be to try to isolate whether the difference between whether a path is finished or not can be fully explained by more objective factors like this, or if there is a human component that we can isolate as well. Eg, are some categories actually more difficult to get to, or do the differences in the target category distributions in the finished and unfinished paths arise because some categories may be more likely to have longer possible shortest paths to them or have fewer links pointing at them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint for dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code saves the version of the dataframe above:\n",
    "finished_paths.to_pickle(os.path.join(GENERATED_METRICS, \"finished_paths_initial_stats.pkl\"))\n",
    "unfinished_paths.to_pickle(os.path.join(GENERATED_METRICS, \"unfinished_paths_initial_stats.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code reads that version of the dataframe from the file:\n",
    "finished_paths = pd.read_pickle(os.path.join(GENERATED_METRICS, \"finished_paths_initial_stats.pkl\"))\n",
    "unfinished_paths = pd.read_pickle(os.path.join(GENERATED_METRICS, \"unfinished_paths_initial_stats.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Putting everything together\n",
    "put all article clicks (before and after giving up, also include all succesfully finished paths) in a wide form df to run statistical anaylsis\n",
    "- merge with article metrics\n",
    "- merge with article categories\n",
    "- merge with game information\n",
    "- merge with player information\n",
    "- merge with backclick information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_information = article_metrics.copy()\n",
    "article_information[\"article_name\"] = article_information[\"file_name\"].apply(lambda name: name.split(\".\")[0])\n",
    "\n",
    "# merge in categories\n",
    "article_information = pd.merge(article_information, categories[[\"article\", \"broad_category\"]], how=\"left\", left_on=\"article_name\", right_on=\"article\")\n",
    "\n",
    "keep = ['article_name',\n",
    "        'word_count',\n",
    "        'non_stopword_count',\n",
    "        'stopword_count',\n",
    "        'avg_word_length',\n",
    "        'avg_sent_length',\n",
    "        'paragraph_count',\n",
    "        'readability_score',\n",
    "        'broad_category']\n",
    "\n",
    "article_information = article_information[keep]\n",
    "article_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration per actual link"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
